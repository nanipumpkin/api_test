{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL that generates the initial CSV list:  https://www.linkedin.com/jobs/search?keywords=junior%20data%20analyst&location=Florianopolis&refresh=true\n"
     ]
    }
   ],
   "source": [
    "# Setup project target, example: Data Science Junior Jobs in Florianopolis\n",
    "url = 'https://www.linkedin.com/jobs/search?keywords=junior%20data%20analyst&location=Florianopolis&refresh=true'\n",
    "print(\"URL that generates the initial CSV list: \", url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29990/1741417621.py:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  wd = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    }
   ],
   "source": [
    "# Setup chromedriver \n",
    "try:\n",
    "    wd = webdriver.Chrome()\n",
    "except:\n",
    "    wd = webdriver.Chrome(ChromeDriverManager().install())\n",
    "wd.get(url)\n",
    "\n",
    "# Loop verifying if a redirect has occurred and then undoes it.\n",
    "while 'authwall' in wd.current_url:\n",
    "    print(wd.current_url)\n",
    "    time.sleep(1)\n",
    "    wd.get(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs found:  218\n"
     ]
    }
   ],
   "source": [
    "# Get the number of jobs available\n",
    "no_of_jobs = int(wd.find_element(By.CSS_SELECTOR, value='h1>span').get_attribute('innerText'))\n",
    "print(\"Number of jobs found: \",no_of_jobs-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Browse all the jobs\n",
    "i = 2\n",
    "while i <= int(no_of_jobs/25)+1: \n",
    "    wd.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "    i = i + 1\n",
    "    try:\n",
    "        wd.find_element(By.XPATH, value='/html/body/div[1]/div/main/section[2]/button').click()\n",
    "        time.sleep(5)\n",
    "    except:\n",
    "        pass\n",
    "        time.sleep(5)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the jobs\n",
    "job_lists = wd.find_element(By.CLASS_NAME, value='jobs-search__results-list')\n",
    "jobs = job_lists.find_elements(By.TAG_NAME, value='li') # return a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalizing job details into dataframe\n",
    "job_id = []\n",
    "job_title = []\n",
    "company_name = []\n",
    "location = []\n",
    "date = []\n",
    "job_link = []\n",
    "jd = []\n",
    "seniority = []\n",
    "emp_type = []\n",
    "job_func = []\n",
    "industries = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading job details into dataframe\n",
    "for job in jobs:\n",
    "        job_id0 = job.find_element(By.CLASS_NAME, value='base-card').get_attribute('data-entity-urn')\n",
    "        job_id.append(job_id0)\n",
    " \n",
    "        job_title0 = job.find_element(By.CSS_SELECTOR, value='h3').text\n",
    "        job_title.append(job_title0)\n",
    " \n",
    "        company_name0 = job.find_element(By.CSS_SELECTOR, value='h4').text\n",
    "        company_name.append(company_name0)\n",
    " \n",
    "        location0 = job.find_element(By.CLASS_NAME, value='job-search-card__location').text\n",
    "        location.append(location0)\n",
    " \n",
    "        date0 = job.find_element(By.CSS_SELECTOR, value='div>div>time').get_attribute('datetime')\n",
    "        date.append(date0)\n",
    " \n",
    "        job_link0 = job.find_element(By.CSS_SELECTOR, value='a').get_attribute('href')\n",
    "        job_link.append(job_link0) \n",
    "\n",
    "\n",
    "        # Creating the soon to be filled columns of each job\n",
    "        \n",
    "        jd.append(\" \")\n",
    "        seniority.append(\" \")\n",
    "        emp_type.append(\" \")\n",
    "        job_func.append(\" \")\n",
    "        industries.append(\" \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extracted job listing links:  220\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of extracted job listing links: \",len(jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into DataFrame for further analysis\n",
    "job_data = pd.DataFrame({'ID': job_id,\n",
    "                         'Date': date,\n",
    "                         'Company': company_name,\n",
    "                         'Title': job_title,\n",
    "                         'Location': location,\n",
    "                         'Link': job_link,\n",
    "                         'Description': jd,\n",
    "                         'Level': seniority,\n",
    "                         'Type': emp_type,\n",
    "                         'Function': job_func,\n",
    "                         'Industry': industries\n",
    "                         })\n",
    "job_data.to_csv('linkedin_jobs_data-3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Scraped Url:\n",
      " https://br.linkedin.com/jobs/view/analista-de-processos-foco-em-analise-de-dados-at-incentiv-me-3272108081?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=fDC%2BEqFkaEXoPx9JoEAyMg%3D%3D&position=1&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "DEBUG:  https://br.linkedin.com/jobs/view/analista-de-processos-foco-em-analise-de-dados-at-incentiv-me-3272108081?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=fDC%2BEqFkaEXoPx9JoEAyMg%3D%3D&position=1&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "\n",
      "        Como Analista de Processos Pleno voc√™ ter√° a miss√£o de contribuir para implementa√ß√£o e manuten√ß√£o do sistema de gest√£o de processos de neg√≥cios e qualidade transformando as fontes de dados em informa√ß√µes, facilitando a tomada de decis√£o dos gestores da empresa, garantindo a ader√™ncia aos par√¢metros das normas e exig√™ncias do mercado, dentro das pol√≠ticas definidas pela empresa.<br><br><strong><u>Ent√£o Se Liga<br><br></u></strong>Nesse sentido precisamos que voc√™ tenha um perfil anal√≠tico, comunicativo, bom racioc√≠nio l√≥gico e que tenha muita proatividade para solucionar os problemas que possam surgir durante a jornada. Se identificou.<br><br><strong>Responsabilidades e atribui√ß√µes<br><br></strong><strong><u>Suas Principais Responsabilidades Ser√£o<br></u></strong><ul><li>Definir padr√µes de coleta, armazenamento, tratamento, an√°lise e aplica√ß√£o de dados essenciais para organiza√ß√£o;</li><li>Orientar os departamentos na elabora√ß√£o e manuten√ß√£o de M√©tricas, Indicadores de desempenho de processos, Acordos de N√≠vel de servi√ßo (ANS) e Acordos de n√≠vel Operacional ( ANO) , conforme os padr√µes estabelecidos;</li><li>Elaborar dashboards voltados ao gerenciamento di√°rio e gest√£o de desempenho. </li><li>Acompanhar o desempenho dos indicadores, realizar an√°lise cr√≠tica e gerenciar os planos de melhoria, conforme os padr√µes estabelecidos;</li><li>Identificar oportunidades, desenhar e conduzir implementa√ß√µes de melhorias nos processos e seus indicadores ;</li><li>Garantir a elabora√ß√£o, manuten√ß√£o ( atualiza√ß√£o, codifica√ß√£o, controle de vers√µes, vencimento) da documenta√ß√£o dos processos da empresa conforme os padr√µes estabelecidos;</li><li>Contribuir com a elabora√ß√£o do plano anual das atividades relacionadas com o sistema de gerenciamento de processos;</li><li>Aplicar ferramentas de resolu√ß√£o de problemas conforme os padr√µes estabelecidos; </li><li>Realizar mapeamento de processos da empresa conforme os padr√µes estabelecidos ( ferramentas, nota√ß√£o);</li><li>Realizar entrevistas, reuni√µes e treinamentos envolvendo grupos espec√≠ficos e/ou todos os colaboradores, visando a multiplica√ß√£o dos conhecimentos e facilitando a implementa√ß√£o do gerenciamento de processos;</li><li>Divulgar a metodologia de gerenciamento de processos e indicadores de desempenho da empresa, atrav√©s da prepara√ß√£o e distribui√ß√£o de material sobre o assunto, organiza√ß√£o de cursos e palestras, programas especiais de divulga√ß√£o, visando a conscientiza√ß√£o e envolvimento de todas as √°reas da empresa;</li><li>Fortalecer a vis√£o sist√™mica e a interrela√ß√£o entre processos, promovendo a conscientiza√ß√£o das pessoas e setores diretamente envolvidos, visando o seu engajamento e sinergia na busca pela melhoria cont√≠nua. <br></li></ul><strong>Requisitos e qualifica√ß√µes<br><br></strong><strong><u>Requisitos<br></u></strong><ul><li>Forma√ß√£o em Engenharia, Administra√ß√£o ou afins;</li><li>Conhecimento em gerenciamento de desempenho dos processos e experi√™ncia na implementa√ß√£o de gest√£o por indicadores de desempenho;</li><li>Conhecimento em ferramentas de avalia√ß√£o e visualiza√ß√£o de dados (Power BI)</li><li>Conhecimento avan√ßado em ferramentas voltadas a cria√ß√£o de tabelas, controles, c√°lculos ( Google Planilhas) </li><li>Conhecimento do padr√£o ( nota√ß√£o) e de ferramentas para mapeamento /desenho de processos - Bizagi</li><li>Conhecimento em gest√£o documental de processos;</li><li>Conhecimento de ferramentas voltadas a resolu√ß√£o de problemas ;</li><li>Conhecimento das melhores pr√°ticas em gerenciamento de processos; </li><li>Conhecimento em gerenciamento de desempenho dos processos;</li><li>Entendimento da amplitude e import√¢ncia dos conceitos e aspectos referentes a gerenciamento de processos;</li><li>Conhecimento avan√ßado de google drive.<br></li></ul><strong><u>Ser√° Um Diferencial Se Voc√™ Tiver<br></u></strong><ul><li>Experi√™ncia na √°rea de tecnologia e startups;</li><li>Conhecimento em metodologia √°gil.</li><li>Conhecimento Filosofia Lean<br></li></ul><strong>Habilidades e Atitudes <br></strong><ul><li>Administra√ß√£o do tempo </li><li>Capacidade de decis√£o </li><li>Comunica√ß√£o </li><li>Controle emocional </li><li>Dilig√™ncia </li><li>Esp√≠rito cr√≠tico </li><li>Imparcialidade </li><li>Lideran√ßa </li><li>Planejamento e controle </li><li>Proatividade </li><li>Relacionamento interpessoal </li><li>Utiliza√ß√£o de racioc√≠nio l√≥gico </li><li>Vis√£o estrat√©gica<br></li></ul><strong>Informa√ß√µes adicionais<br><br></strong>Aqui voc√™ encontrar√° gente do bem, positiva, que ama o que faz e que faz acontecer!<br><br>Gente que acredita na riqueza da diversidade, por isso todas as nossas vagas s√£o trabalhadas pensando em promover e valorizar uma cultura inclusiva que busque a equidade em rela√ß√£o a G√™nero, LGBTQI+, Pessoas com Defici√™ncia, Etnia e Regionalidades.<br><br>A nossa hist√≥ria est√° s√≥ come√ßando e n√≥s sonhamos grande!<br><br>E a√≠, bora fazer parte desse time? üíú\n",
      "      \n",
      "Current Scraped Url:\n",
      " https://br.linkedin.com/jobs/view/sales-operations-sales-data-analyst-at-fiberx-3283612343?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=Qdgb7HAnQy7YOjV7pu4Kxw%3D%3D&position=2&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "DEBUG:  https://br.linkedin.com/jobs/view/sales-operations-sales-data-analyst-at-fiberx-3283612343?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=Qdgb7HAnQy7YOjV7pu4Kxw%3D%3D&position=2&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "\n",
      "        A FiberX est√° com posi√ß√£o para Sales Operation no nosso time de Projetos.<p><br></p>Se voc√™ √© uma pessoa organizada, comprometida tem conhecimento em an√°lise de dados e acompanhamento de KPI's da √°rea comercial, essa oportunidade pode ser sua.<p><br></p><strong><u>Atribui√ß√µes Da Vaga</u></strong><p><br></p><ul><li>Identificar melhorias e automatiza√ß√£o dos processos de vendas tornando ornar os processos mais eficazes e produtivos.</li><li>Avaliar as metodologias de vendas;</li><li>Definir com os times os forecast de vendas;</li><li>An√°lise de dados;</li><li>Identificar e acompanhar m√©tricas, KPIs e metas de vendas;</li><li>Cria√ß√£o de relat√≥rios e dashboards;</li><li>Acompanhamento do processo de vendas;</li><li>Mapeamento e desenho do processo de vendas de projetos complexos;</li><li>Identificar melhorias nos processos e funis de vendas;</li><li>Cria√ß√£o de apresenta√ß√µes executivas em portugu√™s e ingl√™s;</li><li>Acompanhamento de follow ups de projetos.</li></ul><p><br></p><strong><u>Requisitos</u></strong><p><br></p><ul><li>Gradua√ß√£o em Administra√ß√£o, Economia, Engenharias e afins;</li><li>KPI's;</li><li>Sales processes analysis;</li><li>Pipeline Review;</li><li>CRM automation;</li><li>BI Reports;</li><li>Sales frameworks;</li><li>Sales Operations;</li><li>Data Analytics;</li><li>Business Intelligence;</li><li>Excel Avan√ßado;</li><li>Ingl√™s avan√ßado</li></ul><p><br></p><strong><u>Benef√≠cios</u></strong><p><br></p><ul><li>Vale alimenta√ß√£o;</li><li>Seguro de Vida em grupo;</li><li>Plano de Sa√∫de;</li><li>Bolsa Gradua√ß√£o ou P√≥s-gradua√ß√£o;</li><li>Bolsa Idiomas;</li><li>Cultura de Inova√ß√£o;</li><li>Ambiente de aprendizagem.</li></ul><p><br></p>Quer fazer parte desse time que s√≥ cresce? Participe do nosso processo seletivo, n√≥s queremos te conhecer.\n",
      "      \n",
      "Current Scraped Url:\n",
      " https://br.linkedin.com/jobs/view/analista-de-processos-foco-em-analise-de-dados-at-incentiv-3288728174?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=Fb2p0RlDNqka%2BGs1fGbWxQ%3D%3D&position=3&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "DEBUG:  https://br.linkedin.com/jobs/view/analista-de-processos-foco-em-analise-de-dados-at-incentiv-3288728174?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=Fb2p0RlDNqka%2BGs1fGbWxQ%3D%3D&position=3&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "\n",
      "        Atuar√° nas atividades internas e demais fun√ß√µes pertinentes ao cargo. Necess√°rio Conhecimento na √°rea de atua√ß√£o.<br><br><strong><u>Beneficios<br><br></u></strong><strong>Forma√ß√£o Acad√™mica:<br><br></strong>N√£o informado<br><br><strong><u>Sal√°rio<br><br></u></strong><strong>Experi√™ncia:<br><br></strong>A combinar<br><br><strong><u>Cargo<br><br></u></strong>Analista de processos<br><br><strong><u>Empresa<br><br></u></strong>INCENTIV<br><br>Consultoria em publicidade, ag√™ncias de publicidade Agenciamento de espa√ßos para publicidade, exceto em ve√≠culos de comunica√ß√£o e Marketing direto Consultoria em publicidade.<br><br><strong><u>Ramo<br><br></u></strong>Publicidade/ Propaganda\n",
      "      \n",
      "Current Scraped Url:\n",
      " https://br.linkedin.com/jobs/view/analista-de-dados-at-seazone-3273971302?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=dlOlEUQ01jKeDW3VvRBOKA%3D%3D&position=4&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "DEBUG:  https://br.linkedin.com/jobs/view/analista-de-dados-at-seazone-3273971302?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=dlOlEUQ01jKeDW3VvRBOKA%3D%3D&position=4&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "\n",
      "        <strong>Como ser√° um dia de trabalho t√≠pico na Seazone?<br><br></strong>Fazer parte dessa equipe significa que voc√™ ajudar√° a compor um time de excel√™ncia para trabalhar internamente na Seazone.<br><br><strong>O que estamos procurando exatamente?<br><br></strong>De modo geral, procuramos algumas caracter√≠sticas b√°sicas e uma delas √© trazer para trabalhar conosco pessoas que gostem de aprender, que tenham iniciativa, autonomia e vontade de fazer o melhor pelos nossos clientes.<br><br><strong>Responsabilidades e atribui√ß√µes<br></strong><ul><li>An√°lise de dados</li><li>Gera√ß√£o de relat√≥rios</li><li>Cria√ß√£o de dashboards</li><li>Cria√ß√£o de banco de dadosÔªø<br></li></ul><strong>Requisitos e qualifica√ß√µes<br></strong><ul><li>Pensamento anal√≠tico</li><li>Excel intermedi√°rio</li><li>Conhecimento em Power BI ou equivalente<br></li></ul><strong>Informa√ß√µes adicionais<br><br></strong><strong><u>Diferenciais<br></u></strong><ul><li>Excel avan√ßado</li><li>Conhecimento em Python e SQL<br></li></ul><strong><u>ÔªøBenef√≠cios<br></u></strong><ul><li>Hor√°rio flex√≠vel;</li><li>Day-off in birthday;</li><li>Help Tele-Medicina.<br></li></ul><strong><u>Parcerias<br></u></strong><ul><li>Gogood para voc√™ e seus dependentes;</li><li>CCLI idiomas.</li></ul>\n",
      "      \n",
      "Current Scraped Url:\n",
      " https://br.linkedin.com/jobs/view/analista-de-dados-cresol-confedera%C3%A7%C3%A3o-at-cresol-cooperativa-3247509325?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=uAjcICqP4ECM9p3v9Iogcg%3D%3D&position=5&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "DEBUG:  https://br.linkedin.com/jobs/view/analista-de-dados-cresol-confedera%C3%A7%C3%A3o-at-cresol-cooperativa-3247509325?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=uAjcICqP4ECM9p3v9Iogcg%3D%3D&position=5&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "\n",
      "        Estamos em busca de um <strong>Analista de Dados</strong> para somar no nosso time!<br><br>Buscamos profissionais com prop√≥sito, que sonham grande e que acreditam na for√ßa da Coopera√ß√£o!<br><br>Nossa cultura √© focada em um ambiente inclusivo, diverso e colaborativo, permitindo que as pessoas possam ser elas mesmas! Juntos, constru√≠mos valores que s√£o aplicados em nosso dia a dia, no relacionamento com cada cooperado, com o compromisso de tornar a Cresol cada vez mais forte!<br><br>Vem ser Cresol voc√™ tamb√©m!<br><br><strong>Responsabilidades e atribui√ß√µes<br></strong><ul><li>Desenhar e implementar processos de ETL;</li><li>Enriquecer as fontes de dados publicadas na plataforma de B.I. para garantir a qualidade das mesmas bem como das visualiza√ß√µes desenvolvidas;</li><li>Atuar no apoio √† limpeza, enriquecimento, modelagem e transforma√ß√£o dos dados, utilizando fontes de dados j√° existentes, ou fontes de dados externas;</li><li>Auxiliar tecnicamente os times quando ocorrerem d√∫vidas sobre os dados e o funcionamento das integra√ß√µes, fontes de dados e visualiza√ß√µes.<br></li></ul><strong>Requisitos e qualifica√ß√µes<br></strong><ul><li>Ensino superior em andamento em Sistema de Informa√ß√£o, An√°lise de Dados, Computa√ß√£o, Contabilidade, matem√°tica, estat√≠stica ou √°reas afins,</li><li>Viv√™ncia em Bancos de Dados; </li><li>Pensamento l√≥gico, explorat√≥rio e investigativo; </li><li>Metodologias √°geis;</li><li>Viv√™ncia com engenharia de dados;</li><li>Conhecer conceitos do mercado de institui√ß√µes financeiras (Bancos ou Cooperativas por exemplo); </li><li>Viv√™ncia com desenvolvimento de scripts em alguma linguagem (por exemplo Python); </li><li>Ter trabalhado com grandes volumes de dados; </li><li>Experi√™ncia com cria√ß√£o e manuten√ß√£o de consultas SQL. </li><li>Ambiente Cloud.<br></li></ul><strong>Informa√ß√µes adicionais<br><br></strong><strong><u>Benef√≠cios<br></u></strong><ul><li>Vale Alimenta√ß√£o e/ou Refei√ß√£o ‚Äì para comprar seu alimento e aproveitar do seu jeito;</li><li>Seguro de Vida - um cuidado a mais que tamb√©m pode ser acionado em casos de Doen√ßas Graves e Aux√≠lio Funeral, aquela ajuda na hora que mais precisamos;</li><li>Plano de Sa√∫de - a mensalidade √© um presente da Cresol para o colaborador, estamos sempre juntos;</li><li>Plano Odontol√≥gico - a mensalidade √© um presente da Cresol para o colaborador;</li><li>Previd√™ncia Privada - a Cresol se preocupa com seu futuro;</li><li>PPR (Programa de Participa√ß√£o nos Resultados) ‚Äì conquistamos juntos e celebramos juntos; </li><li>Cart√£o Natal ‚Äì a Cresol fornece um cart√£o no Natal no final do ano, assim a ceia √© do jeito que o colaborador gosta;</li><li>Aux√≠lio Creche - a Cresol cuida tamb√©m do bem estar dos filhos dos colaboradores; </li><li>Desenvolvimento ‚Äì a Cresol acredita no desenvolvimento dos colaboradores e investe nele durante o ano; </li><li>Cresol Acolhe ‚Äì para o colaborador e sua Fam√≠lia, aqui oferecemos desde suporte a d√∫vidas jur√≠dicas como dicas para seu Pet, por meio de liga√ß√µes de qualquer lugar do Brasil;</li><li>Gympass - Acesso a academias f√≠sicas e aulas de Yoga, Medita√ß√£o e Funcional ao vivo, um benef√≠cio completo para o seu Bem Estar.</li></ul>\n",
      "      \n",
      "Current Scraped Url:\n",
      " https://br.linkedin.com/jobs/view/analista-de-dados-cresol-confedera%C3%A7%C3%A3o-at-cresol-cooperativa-3247510275?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=kePvdOyCaUudr55wqh%2FARA%3D%3D&position=6&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "DEBUG:  https://br.linkedin.com/jobs/view/analista-de-dados-cresol-confedera%C3%A7%C3%A3o-at-cresol-cooperativa-3247510275?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=kePvdOyCaUudr55wqh%2FARA%3D%3D&position=6&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "\n",
      "        Estamos em busca de um <strong>Analista de Dados</strong> para somar no nosso time!<br><br>Buscamos profissionais com prop√≥sito, que sonham grande e que acreditam na for√ßa da Coopera√ß√£o!<br><br>Nossa cultura √© focada em um ambiente inclusivo, diverso e colaborativo, permitindo que as pessoas possam ser elas mesmas! Juntos, constru√≠mos valores que s√£o aplicados em nosso dia a dia, no relacionamento com cada cooperado, com o compromisso de tornar a Cresol cada vez mais forte!<br><br>Vem ser Cresol voc√™ tamb√©m!<br><br><strong>Responsabilidades e atribui√ß√µes<br></strong><ul><li>Realizar as atividades inerentes √† an√°lise e corre√ß√£o de dados, dimensionando requisitos, providenciando a coleta e extra√ß√£o de dados, realizando a an√°lise, monitoramento e corre√ß√£o de dados, com o objetivo de garantir a disponibiliza√ß√£o de dados e informa√ß√µes precisas para execu√ß√£o dos processos e para a tomada de decis√µes;</li><li>Desenhar e implementar processos de ETL;</li><li>Enriquecer as fontes de dados publicadas na plataforma de B.I. para garantir a qualidade das mesmas bem como das visualiza√ß√µes desenvolvidas;</li><li>Atuar no apoio √† limpeza, enriquecimento, modelagem e transforma√ß√£o dos dados, utilizando fontes de dados j√° existentes, ou fontes de dados externas;</li><li>Auxiliar tecnicamente os times quando ocorrerem d√∫vidas sobre os dados e o funcionamento das integra√ß√µes, fontes de dados e visualiza√ß√µes.<br></li></ul><strong>Requisitos e qualifica√ß√µes<br></strong><ul><li>Ensino superior em andamento em Sistema de Informa√ß√£o, An√°lise de Dados, Computa√ß√£o, Contabilidade, matem√°tica, estat√≠stica ou √°reas afins,</li><li>Viv√™ncia em Bancos de Dados; </li><li>Pensamento l√≥gico, explorat√≥rio e investigativo; </li><li>Metodologias √°geis;</li><li>Viv√™ncia com engenharia de dados;</li><li>Conhecer conceitos do mercado de institui√ß√µes financeiras (Bancos ou Cooperativas por exemplo); </li><li>Viv√™ncia com desenvolvimento de scripts em alguma linguagem (por exemplo Python); </li><li>Ter trabalhado com grandes volumes de dados; </li><li>Experi√™ncia com cria√ß√£o e manuten√ß√£o de consultas SQL;</li><li>Ambiente Cloud.<br></li></ul><strong>Informa√ß√µes adicionais<br><br></strong><strong><u>Benef√≠cios<br></u></strong><ul><li>Vale Alimenta√ß√£o e/ou Refei√ß√£o ‚Äì para comprar seu alimento e aproveitar do seu jeito;</li><li>Seguro de Vida - um cuidado a mais que tamb√©m pode ser acionado em casos de Doen√ßas Graves e Aux√≠lio Funeral, aquela ajuda na hora que mais precisamos;</li><li>Plano de Sa√∫de - a mensalidade √© um presente da Cresol para o colaborador, estamos sempre juntos;</li><li>Plano Odontol√≥gico - a mensalidade √© um presente da Cresol para o colaborador;</li><li>Previd√™ncia Privada - a Cresol se preocupa com seu futuro;</li><li>PPR (Programa de Participa√ß√£o nos Resultados) ‚Äì conquistamos juntos e celebramos juntos; </li><li>Cart√£o Natal ‚Äì a Cresol fornece um cart√£o no Natal no final do ano, assim a ceia √© do jeito que o colaborador gosta;</li><li>Aux√≠lio Creche - a Cresol cuida tamb√©m do bem estar dos filhos dos colaboradores; </li><li>Desenvolvimento ‚Äì a Cresol acredita no desenvolvimento dos colaboradores e investe nele durante o ano; </li><li>Cresol Acolhe ‚Äì para o colaborador e sua Fam√≠lia, aqui oferecemos desde suporte a d√∫vidas jur√≠dicas como dicas para seu Pet, por meio de liga√ß√µes de qualquer lugar do Brasil;</li><li>Gympass - Acesso a academias f√≠sicas e aulas de Yoga, Medita√ß√£o e Funcional ao vivo, um benef√≠cio completo para o seu Bem Estar.</li></ul>\n",
      "      \n",
      "Current Scraped Url:\n",
      " https://br.linkedin.com/jobs/view/analista-de-dados-at-dynamox-3269138473?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=gYQRjl9XHaqOcOx6%2Bm%2FSUA%3D%3D&position=7&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "DEBUG:  https://br.linkedin.com/jobs/view/analista-de-dados-at-dynamox-3269138473?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=gYQRjl9XHaqOcOx6%2Bm%2FSUA%3D%3D&position=7&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "\n",
      "        Sobre n√≥s:<p><br></p>A DYNAMOX √© uma empresa de alta tecnologia que desenvolve sistemas de monitoramento e aquisi√ß√£o de dados de vibra√ß√£o e temperatura. Especialista em an√°lise de vibra√ß√µes e monitoramento da condi√ß√£o de ativos industriais. Solu√ß√£o ideal para a manuten√ß√£o preditiva. A Dynamox conta com um departamento de P&amp;D que desenvolve sistemas completos: hardware ao software industrial.<p><br></p>Somos excel√™ncia no que fazemos: empresa certificada ISO 9001, 27001 e Great Place to Work!<p><br></p>Se identificou? Ent√£o vem fazer parte do nosso DynaTeam!<p><br></p>O que estamos buscando:<p><br></p>Pessoa respons√°vel por desenvolver e implementar an√°lises de dados, gera√ß√£o de relat√≥rios e outras estrat√©gias com foco no aumento da performance e escalabilidade do produto, com impacto na melhoria da experi√™ncia dos clientes.<p><br></p>Responsabilidades e atribui√ß√µes:<p><br></p><ul><li>Gerar m√©tricas e monitorar indicadores da ader√™ncia dos usu√°rios e da performance da solu√ß√£o;</li><li>Validar a experi√™ncia do cliente quanto √† usabilidade e ao desempenho do produto;</li><li>Identificar e discutir pontos de melhoria dos produtos com times de desenvolvimento;</li><li>Reunir-se com representantes comerciais e clientes para defini√ß√£o de escopo de ferramentas e investiga√ß√£o de problemas;</li><li>Extrair e transformar dados de bancos de dados e logs de sistema para cria√ß√£o de relat√≥rios de indicadores, bases de dados e apresenta√ß√µes;</li><li>Seguir planejamento para desenvolvimento e manuten√ß√£o de algoritmos de automa√ß√£o e ferramentas;</li><li>Organizar e executar testes de valida√ß√£o de novas features, prot√≥tipos e produtos;</li><li>Produzir documenta√ß√µes, disseminar padr√µes e difundir informa√ß√µes t√©cnicas acerca dos produtos;</li><li>Contribuir e disseminar pr√°ticas de seguran√ßa de informa√ß√£o e privacidade de dados confidenciais e restritos, no que diz respeito √†s rotinas do departamento e empresa.</li></ul><p><br></p>Requisitos e Qualifica√ß√µes:<p><br></p><ul><li>Perfil anal√≠tico, comunicador e solucionador;</li><li>Experi√™ncia acad√™mica ou profissional em an√°lise de dados;</li><li>Conhecimento em l√≥gicas e linguagens de programa√ß√£o - desej√°vel Python;</li><li>Ingl√™s t√©cnico, desej√°vel espanhol.</li></ul><p><br></p>Forma√ß√£o:<p><br></p><ul><li>Ensino superior completo em Engenharias, Automa√ß√£o Industrial, Ci√™ncias da Computa√ß√£o, Sistemas de Informa√ß√£o ou √°reas correlatas.</li></ul><p><br></p>Ser√° um diferencial se:<p><br></p><ul><li>Ser√° um diferencial se tiver experi√™ncia com gest√£o de projetos e/ou lideran√ßa de equipes;</li><li>Ser√° um diferencial se tiver experi√™ncia com ferramentas de Business Intelligence (PowerBI, Datastudio e afins);</li><li>Ser√° um diferencial se tiver experi√™ncia com ferramentas de Gest√£o de Desenvolvimento (Jira, Git e afins);</li><li>Ser√° um diferencial se tiver no√ß√µes de eletr√¥nica, telecomunica√ß√µes, redes de computadores ou ativos industriais;</li><li>Ser√° um diferencial se tiver no√ß√µes de opera√ß√µes de streaming de dados (Kafka), de bancos de dados (Mongo, Big Query) e/ou integra√ß√µes de dados (APIs).</li></ul><p><br></p>Benef√≠cios:<p><br></p><ul><li>Vale transporte OU Aux√≠lio deslocamentos sem desconto em folha;</li><li>Vale alimenta√ß√£o/refei√ß√£o flex√≠vel sem desconto em folha;</li><li>Seguro de vida global;</li><li>Plano de sa√∫de custeado pela empresa ap√≥s o per√≠odo de experi√™ncia;</li><li>Plano odontol√≥gico custeado pela empresa ap√≥s o per√≠odo de experi√™ncia;</li><li>Conv√™nio com Farmasesi e OdontoSesi;</li><li>Conv√™nio GoGood - Plataforma de bem-estar;</li><li>Atendimento com fisioterapeuta/osteopata na empresa;</li><li>Sala de descompress√£o com puffs, jogos e videogames;</li><li>Frutas e caf√© √† vontade;</li><li>No dress code;</li><li>A vista de nosso escrit√≥rio √© incr√≠vel! Empresa situada no parque tecnol√≥gico de Florian√≥polis.</li></ul><p><br></p>VAGA PRESENCIAL - CLT - 44h\n",
      "      \n",
      "Current Scraped Url:\n",
      " https://br.linkedin.com/jobs/view/engenheira-o-de-dados-j%C3%BAnior-remoto-at-bix-tecnologia-consultoria-de-dados-3247489068?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=KILiqr0AFwy62lZMX5b6Ww%3D%3D&position=8&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "DEBUG:  https://www.linkedin.com/authwall?trk=qf&original_referer=&sessionRedirect=https%3A%2F%2Fbr.linkedin.com%2Fjobs%2Fview%2Fengenheira-o-de-dados-j%25C3%25BAnior-remoto-at-bix-tecnologia-consultoria-de-dados-3247489068%3FrefId%3DM3gvRWmiPk9RfbiFbr9yRA%253D%253D%26trackingId%3DKILiqr0AFwy62lZMX5b6Ww%253D%253D%26position%3D8%26pageNum%3D0%26trk%3Dpublic_jobs_jserp-result_search-card\n",
      "https://www.linkedin.com/authwall?trk=qf&original_referer=&sessionRedirect=https%3A%2F%2Fbr.linkedin.com%2Fjobs%2Fview%2Fengenheira-o-de-dados-j%25C3%25BAnior-remoto-at-bix-tecnologia-consultoria-de-dados-3247489068%3FrefId%3DM3gvRWmiPk9RfbiFbr9yRA%253D%253D%26trackingId%3DKILiqr0AFwy62lZMX5b6Ww%253D%253D%26position%3D8%26pageNum%3D0%26trk%3Dpublic_jobs_jserp-result_search-card\n",
      "\n",
      "        Somos uma empresa apaixonada por pessoas, pautamos sempre pela qualidade das nossas rela√ß√µes e pelo cuidado com cada membro do time. Estamos buscando uma pessoa para fazer parte deste time que vem crescendo a cada dia, tanto em n√∫mero quanto em desenvolvimento.<br><br>Encorajamos e acreditamos no nosso time e prezamos por fazer junto. Se voc√™ √© essa pessoa, que tem um senso de equipe e que procura por desenvolvimento constante, a BIX √© para voc√™!<br><br>Vem fazer parte da BIX Tecnologia!<br><br>O que esperamos ver em voc√™:<br><ul><li>Comunica√ß√£o e Relacionamento Interpessoal;</li><li>Resolu√ß√£o de Problemas;</li><li>Interesse e Capacidade de Aprendizagem;</li><li>Gest√£o do Tempo e Planejamento;</li><li>Capacidade Anal√≠tica.<br></li></ul>O que esperamos que voc√™ tenha:<br><ul><li>Experi√™ncia em Python, Java ou Scala;</li><li>Conhecimento avan√ßado em SQL;</li><li>Conhecimento em Git e versionamento de c√≥digo;</li><li>Ensino Superior cursando ou completo, em √°reas correlatas a sua fun√ß√£o: engenharias, cursos de computa√ß√£o e cursos relacionados √† √°rea de exatas.<br></li></ul>O que voc√™ far√° em seu dia a dia:<br><ul><li>Criar pipelines de dados, utilizando python e sql, para ingerir e transformar dados para o time de neg√≥cio, sempre que existir demanda;</li><li>Orquestrar pipelines, utilizando Apache Airflow, para sequenciar e automatizar tarefas a cada novo pipeline desenvolvido;</li><li>Armazenar dados em Data Lakes, utilizando AWS S3, Google Cloud Storage ou Azure Data Lake Storage Gen2, sempre que houver uma solicita√ß√£o do cliente;</li><li>Realizar reuni√µes com clientes, por meio de videoconfer√™ncia, desenvolvendo os questionamentos estrat√©gicos voltados ao seu neg√≥cio/processo, a cada in√≠cio de projeto ou sprint;</li><li>Criar e manter a documenta√ß√£o do sistema, utilizando Notion, para ajudar na gest√£o de conhecimento, a cada novo projeto.<br></li></ul>O que a BIX oferece para voc√™:<br><ul><li>Cart√£o de benef√≠cios flex√≠veis;</li><li>Plataforma de terapia e nutricionistas online;</li><li>Plano de sa√∫de e Odontol√≥gico;</li><li>Plano de carreira acelerado;</li><li>Participa√ß√£o nos resultados;</li><li>Contato direto com l√≠deres de grandes empresas;</li><li>Ambiente diferenciado (Hora BIX, integra√ß√µes e Happy Hours, Programa de Mentoria, Reuni√µes 1on1);</li><li>Aulas on-line de ingl√™s (cambly);</li><li>Folga no anivers√°rio;</li><li>Trabalho remoto.<br></li></ul>Em caso de d√∫vidas, entrar em contato por e-mail: talentos@bixtecnologia.com.br.\n",
      "      \n",
      "Current Scraped Url:\n",
      " https://br.linkedin.com/jobs/view/analista-de-dados-at-3neuron-3255755934?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=1mTH8xfNBrnCrIpRbyi9Cw%3D%3D&position=9&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "DEBUG:  https://br.linkedin.com/jobs/view/analista-de-dados-at-3neuron-3255755934?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=1mTH8xfNBrnCrIpRbyi9Cw%3D%3D&position=9&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "\n",
      "        Quer se juntar a um time de profissionais com viv√™ncia multidisciplinar nas mais diversas √°reas de conhecimento em um ambiente de alto desempenho?<p><br></p><strong>Venha para 3NEURON!</strong><p><br></p>Estamos buscando candidatos que abracem desafios de transforma√ß√£o digital e an√°lise de dados. Se voc√™ deseja crescer junto com a gente, n√£o perca tempo! Inscreva-se no processo seletivo!<p><br></p><strong>REQUISITOS</strong><p><br></p><ul><li>Boa comunica√ß√£o visando o mapeamento de requisitos e apresenta√ß√£o das solu√ß√µes desenvolvidas;</li><li>Conhecimento em Metodologias desenvolvimento lean/agile;</li><li>Conhecimento em Data Modeling;</li><li>Conhecimento em Plataformas de Nuvem do mercado (Amazon Web Services, Google Cloud e Microsoft Azure);</li><li>Experi√™ncia com solu√ß√µes para constru√ß√£o dos processos de ETL;</li><li>Conhecimento em Linguagens de programa√ß√£o (SQL, Shell Script, R, Pyhton, Scala, Java, etc.);</li><li>Experi√™ncia no desenvolvimento de Dashboards com Microsoft Power BI.</li></ul><p><br></p><strong>ATIVIDADES</strong><p><br></p><ul><li>Atuar no planejamento de projetos para dimensionamento da infraestrutura de BI e modelos de dados junto aos clientes;</li><li>Trabalhar com os consultores e analistas de neg√≥cios para alinhamento com as estrat√©gias e objetivos de neg√≥cio;</li><li>Extrair os dados de diversas fontes de dados para ingest√£o nas plataformas de an√°lise de dados;</li><li>Assegurar que os dados sejam apropriados, acess√≠veis e dispon√≠veis;</li><li>Construir dashboards para visualiza√ß√£o de dados;</li><li>Prover a manuten√ß√£o e a disponibilidade da solu√ß√£o de BI;</li><li>Otimizar a performance e escalabilidade;</li><li>Identificar oportunidades para aquisi√ß√£o de dados.</li></ul><p><br></p><strong>BENEF√çCIOS</strong><p><br></p><ul><li>Desenvolvimento profissional em projetos de diversas √°rea e segmentos;</li><li>Incentivo √†s certifica√ß√µes;</li><li>Participa√ß√£o do Programa de Forma√ß√£o de Consultores 3ENURON e acesso aos materiais da Universidade 3NEURON;</li><li>Avalia√ß√£o de Desempenho de 6 em 6 meses, com possibilidade de progress√£o anual de acordo com o seu desempenho;</li><li>Sal√°rio compat√≠vel com o mercado;</li><li>Vale alimenta√ß√£o/refei√ß√£o;</li><li>Programa de Premia√ß√£o por performance.</li></ul>\n",
      "      \n",
      "Current Scraped Url:\n",
      " https://br.linkedin.com/jobs/view/analista-de-dados-growth-at-pieta-tech-3254129678?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=MhGlaPZmUOeDDb5q5Xn5hA%3D%3D&position=10&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "DEBUG:  https://br.linkedin.com/jobs/view/analista-de-dados-growth-at-pieta-tech-3254129678?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=MhGlaPZmUOeDDb5q5Xn5hA%3D%3D&position=10&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "\n",
      "        Estamos em constante expans√£o!<p><br></p>Com mais de 5.000 projetos homologados em 45 distribuidoras por todo Brasil e tr√™s softwares desenvolvidos, nosso prop√≥sito √© levar solu√ß√µes inteligentes e eficientes para o mercado fotovoltaico, al√©m de produzir conte√∫do de valor para propagar conhecimento dentro do setor.<p><br></p>E para que seja poss√≠vel nos aperfei√ßoarmos ainda mais, contamos e buscamos por pessoas que querem fazer a diferen√ßa e que unem as suas especialidades e experi√™ncias em prol da inova√ß√£o.<p><br></p>Ent√£o, que tal fazer parte de uma energytech pioneira no mercado de energia solar no Brasil? Se voc√™ possui esp√≠rito empreendedor, aspira inova√ß√£o e quer fazer parte de um time de alto desempenho, candidate-se √†s nossas vagas!<p><br></p>O seu desafio ser√°:<p><br></p><ul><li></li><li>Respons√°vel pela estrutura√ß√£o e gest√£o de dados;</li><li>Cria√ß√£o de dashboards e relat√≥rios;</li><li>Integra√ß√£o dos dados nas plataformas;</li><li>Acompanhamento de testes;</li><li>Relat√≥rios de testes;</li><li>Apoio t√©cnico para automa√ß√µes;</li><li>Cria√ß√£o de hip√≥teses de melhoria dos processos baseadas em dados;</li><li>Mapear e propor melhorias na estrat√©gia;</li><li>Analisar oportunidades em cada etapa do funil de marketing e vendas, identificando a√ß√µes espec√≠ficas para cada uma delas.</li></ul><p><br></p>O que voc√™ traz:<p><br></p><ul><li>Esp√≠rito empreendedor;</li><li>Experi√™ncia com an√°lise de dados;</li><li>Estat√≠stica avan√ßada;</li><li>Dom√≠nio de plataformas de automa√ß√£o de marketing (Active Campaign ou semelhante).</li><li>Experi√™ncia com ferramentas de an√°lise web (Google Analytics, Hotjar, Microsoft Clarity,etc);</li><li>Conhecimento de linguagem de programa√ß√£o SQL;</li><li>Conhecimento em linguagem de programa√ß√£o Python;</li></ul><p><br></p>Ser√° um plus se voc√™ tiver:<p><br></p><ul><li>Experi√™ncia com Startups.</li></ul><p><br></p>Algumas das nossas pol√≠ticas e benef√≠cios s√£o:<p><br></p><ul><li>Aux√≠lio Transporte;</li><li>Plano de Sa√∫de - Unimed*;</li><li>Vale alimenta√ß√£o;</li><li>Day Off para aniversariantes;</li><li>Hor√°rio flex√≠vel;</li><li>Open Fruta;</li><li>Caf√© expresso, capuccino, mocaccino e chocolate quente;</li><li>Parceria com estabelecimentos;</li><li>Ambiente leve e descontra√≠do;</li><li>Espa√ßo para descanso;</li><li>Happy Hour.</li></ul>\n",
      "      \n",
      "Current Scraped Url:\n",
      " https://br.linkedin.com/jobs/view/engenheiro-a-de-dados-j%C3%BAnior-at-dot-digital-group-3274894028?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=yal5%2B1JpVrsz9ZpyMmmDqA%3D%3D&position=11&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "DEBUG:  https://br.linkedin.com/jobs/view/engenheiro-a-de-dados-j%C3%BAnior-at-dot-digital-group-3274894028?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=yal5%2B1JpVrsz9ZpyMmmDqA%3D%3D&position=11&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "\n",
      "        <strong>Descri√ß√£o</strong><p><br></p><strong><strong>ü§©QUEM SOMOS?</strong></strong><p><br></p>O DOT Digital Group √© pioneiro no mercado de Educa√ß√£o Corporativa Digital no Brasil! J√° s√£o mais de 25 anos sendo respons√°vel pela transforma√ß√£o de muitos neg√≥cios que decidiram abra√ßar a Tecnologia e a Transforma√ß√£o Digital. Estamos acostumados a abra√ßar os desafios educacionais mais diversos ‚Äì do simples ao complexo. Educa√ß√£o e tecnologia √© o nosso neg√≥cio!<p><br></p><strong><strong>üßêO QUE FAZEMOS?</strong></strong><p><br></p>Desenvolvemos pessoas para impulsionar organiza√ß√µes! Produ√ß√£o de cursos online e trilhas de aprendizagem sob medida, estrutura√ß√£o de Universidades Corporativas, desenvolvimento de solu√ß√µes como LMS, Immersive Learning e Gamification, desenvolvimento de conte√∫do educacional para o formato digital, opera√ß√µes em larga escala de monitoria e tutoria, entre outras estrat√©gias educacionais.<p><br></p><strong><strong>ü§óNOSSO JEITO DOT DE SER!</strong></strong><p><br></p>Jogamos aberto e limpo, estamos no mesmo barco e n√£o tiramos o corpo fora! Aqui <strong>respeitamos</strong> as pessoas - independente da cor, cren√ßas, cultura, g√™nero, orienta√ß√£o afetiva e idade. Acreditamos no que fazemos e temos paix√£o pelo UAU. Sempre √© poss√≠vel fazer diferente e melhor em um ambiente de confian√ßa. Valorizamos a autogest√£o, a colabora√ß√£o e a busca pelo desenvolvimento cont√≠nuo. E a√≠, curtiu e se identificou com o jeito DOT de ser? Ent√£o #vemproDOT!<p><br></p><strong>üéØEngenheiro(a) de Dados J√∫nior</strong><p><br></p>Voc√™ que tem perfil anal√≠tico, curte desenvolver, testar, alinhar arquiteturas, e utilizar dados para automatiza√ß√£o e melhorias na √°rea, vem pro DOT! N√≥s acreditamos no que fazemos e buscamos algu√©m que embarque nessa com a gente.<p><br></p><strong>Qual o seu papel na constru√ß√£o dessa trilha?</strong><p><br></p><ul><li>Desenvolver ETLs e pipelines de integra√ß√£o de dados;</li><li>Auxiliar em desenvolver, construir, testar, manter e alinhar arquiteturas com requisitos de neg√≥cios;</li><li>Usar grandes conjuntos de dados para resolver problemas de neg√≥cios;</li><li>Contribuir e auxiliar os demais membros da equipe, oferecendo suporte e solu√ß√µes t√©cnicas.</li></ul><p><br></p><strong>Quais viv√™ncias esperamos de voc√™?</strong><p><br></p><ul><li>Viv√™ncia em Python e SQL para manipula√ß√£o de dados;</li><li>Viv√™ncia em processdamento de dados em larga escala com spark (pyspark);</li><li>Viv√™ncia em orquestra√ß√£o de dados com Apache Airflow.</li></ul><p><br></p><strong><u>Ser√° Incr√≠vel Se Voc√™ J√° Tiver</u></strong><p><br></p><ul><li>Viv√™ncia em Infrastructure as code (Docker, Kubernetes, Terraform);</li><li>Conhecimento em alguma ferramenta de dashboard (Data Studio, Power Bi, Tableau ou QlikView).</li></ul><p><br></p>Aqui acreditamos no lifelong learning, e desejamos que voc√™ siga em busca de aprendizado cont√≠nuo!<p><br></p><strong><u>ü•≥nossa Proposta De Valor</u></strong><p><br></p>E para impulsionar voc√™ a completar essa trilha com sucesso, o DOT oferece:<p><br></p><strong>Aux√≠lios!</strong><p><br></p><ul><li>Vale alimenta√ß√£o e/ou refei√ß√£o, com desconto de apenas 1% na folha (R$660);</li><li>Vale transporte;</li><li>Seguro de vida;</li><li>Aux√≠lio home office (R$100);</li><li>Aux√≠lio creche;</li><li>Headhunter (valor por indica√ß√£o de colaborador);</li><li>Indica√ß√£o de clientes (valor por indica√ß√£o de clientes).</li></ul><p><br></p><strong>Sa√∫de e bem estar!</strong><p><br></p><ul><li>Plano de sa√∫de integral, sem desconto na folha (com terapia online gratuita);</li><li>Conv√™nio odontol√≥gico;</li><li>Gympass (plataforma de sa√∫de e bem estar);</li><li>Conv√™nio Farm√°cia;</li><li>Licen√ßa maternidade estendida de 6 meses;</li><li>Licen√ßa paternidade estendida de 20 dias;</li><li>FeelingDOT sobre temas diversos (workshops sobre autoconhecimento, diversidade, inclus√£o e equil√≠brio);</li><li>Mimos e gifts em datas comemorativas.</li></ul><p><br></p><strong>Crescimento e desenvolvimento cont√≠nuos!</strong><p><br></p><ul><li>Verba de Sophia de R$ 2.000,00 (aux√≠lio educa√ß√£o);</li><li>Horas de Sophia (40 horas/ano em capacita√ß√£o da sua escolha);</li><li>Verba Survival (aux√≠lio educa√ß√£o no neg√≥cio);</li><li>DOTAcademy com cursos gratuitos;</li><li>Plataforma que apoia no desenvolvimento de carreira;</li><li>Mobilidade interna;</li><li>DOTHUB (desenvolvimento de lideran√ßas);</li><li>Cultura de feedback;</li><li>DOTKnows (peer learning).</li></ul><p><br></p><strong>Clima colaborativo e descontra√≠do!</strong><p><br></p><ul><li>Anywhereoffice: trabalhe de onde quiser;</li><li>Hor√°rio flex√≠vel;</li><li>Aprendizado cont√≠nuo;</li><li>Pessoas que √© bom de estar perto;</li><li>Autonomia com responsabilidade;</li><li>Local para refei√ß√µes (presencial);</li><li>Lanches, snacks, frutas, ch√°s e caf√© passado (presencial);</li><li>√Årea de conviv√™ncia (presencial);</li><li>Momentos de integra√ß√£o e festas.</li></ul><p><br></p>E muuuito mais! ;)<p><br></p><strong>Caracter√≠sticas</strong> <strong>Tipo de Contrata√ß√£o</strong><p><br></p>Tempo integral<p><br></p><strong>Remunera√ß√£o</strong><p><br></p>Competitivo<p><br></p><strong>Outras Caracter√≠sticas</strong><p><br></p>Trabalho remoto<p><br></p>\n",
      "      \n",
      "Current Scraped Url:\n",
      " https://br.linkedin.com/jobs/view/engenheiro-de-dados-at-fator-wow%21-3274713572?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=hQbXg7wqOtG2JZY0hy2Alg%3D%3D&position=12&pageNum=0&trk=public_jobs_jserp-result_search-card\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [248], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m url \u001b[38;5;241m=\u001b[39m job[\u001b[38;5;241m5\u001b[39m]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent Scraped Url:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,url)\n\u001b[0;32m---> 19\u001b[0m wd\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEBUG: \u001b[39m\u001b[38;5;124m\"\u001b[39m, wd\u001b[38;5;241m.\u001b[39mcurrent_url)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Loop verifying if a redirect has occurred and then undoes it.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/git/web_scraping_jobs/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, url: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[39m    Loads a web page in the current browser session.\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mGET, {\u001b[39m'\u001b[39;49m\u001b[39murl\u001b[39;49m\u001b[39m'\u001b[39;49m: url})\n",
      "File \u001b[0;32m~/Desktop/git/web_scraping_jobs/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:426\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    423\u001b[0m         params[\u001b[39m'\u001b[39m\u001b[39msessionId\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession_id\n\u001b[1;32m    425\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_value(params)\n\u001b[0;32m--> 426\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcommand_executor\u001b[39m.\u001b[39;49mexecute(driver_command, params)\n\u001b[1;32m    427\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[1;32m    428\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_handler\u001b[39m.\u001b[39mcheck_response(response)\n",
      "File \u001b[0;32m~/Desktop/git/web_scraping_jobs/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py:344\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    342\u001b[0m data \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mdump_json(params)\n\u001b[1;32m    343\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_url\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 344\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(command_info[\u001b[39m0\u001b[39;49m], url, body\u001b[39m=\u001b[39;49mdata)\n",
      "File \u001b[0;32m~/Desktop/git/web_scraping_jobs/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py:366\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    363\u001b[0m     body \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeep_alive:\n\u001b[0;32m--> 366\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conn\u001b[39m.\u001b[39;49mrequest(method, url, body\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[1;32m    367\u001b[0m     statuscode \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mstatus\n\u001b[1;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/git/web_scraping_jobs/venv/lib/python3.10/site-packages/urllib3/request.py:78\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_encode_url(\n\u001b[1;32m     75\u001b[0m         method, url, fields\u001b[39m=\u001b[39mfields, headers\u001b[39m=\u001b[39mheaders, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39murlopen_kw\n\u001b[1;32m     76\u001b[0m     )\n\u001b[1;32m     77\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_encode_body(\n\u001b[1;32m     79\u001b[0m         method, url, fields\u001b[39m=\u001b[39;49mfields, headers\u001b[39m=\u001b[39;49mheaders, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49murlopen_kw\n\u001b[1;32m     80\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/git/web_scraping_jobs/venv/lib/python3.10/site-packages/urllib3/request.py:170\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m extra_kw[\u001b[39m\"\u001b[39m\u001b[39mheaders\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mupdate(headers)\n\u001b[1;32m    168\u001b[0m extra_kw\u001b[39m.\u001b[39mupdate(urlopen_kw)\n\u001b[0;32m--> 170\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kw)\n",
      "File \u001b[0;32m~/Desktop/git/web_scraping_jobs/venv/lib/python3.10/site-packages/urllib3/poolmanager.py:376\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    374\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[1;32m    375\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(method, u\u001b[39m.\u001b[39;49mrequest_uri, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    378\u001b[0m redirect_location \u001b[39m=\u001b[39m redirect \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mget_redirect_location()\n\u001b[1;32m    379\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[0;32m~/Desktop/git/web_scraping_jobs/venv/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/git/web_scraping_jobs/venv/lib/python3.10/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/git/web_scraping_jobs/venv/lib/python3.10/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1375\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load further details\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "filename = 'linkedin_jobs_data-3.csv'\n",
    "# Opening csv file to read job links\n",
    "\n",
    "with open(filename, 'r') as csvfile: \n",
    "    csvreader = csv.reader(csvfile)\n",
    "    next(csvreader)\n",
    "\n",
    "    # Indicates which job is going to be updated\n",
    "    CSVtabelIndex = 0\n",
    "\n",
    "    for job in csvreader:\n",
    "        \n",
    "        url = job[5]\n",
    "        print(\"Current Scraped Url:\\n\",url)\n",
    "        wd.get(url)\n",
    "\n",
    "        print(\"DEBUG: \", wd.current_url)\n",
    "\n",
    "        # Loop verifying if a redirect has occurred and then undoes it.\n",
    "        while 'authwall' in wd.current_url:\n",
    "            print(wd.current_url)\n",
    "            time.sleep(2)\n",
    "            wd.get(url)\n",
    "\n",
    "        # Selecting elements that hold the job description (about)\n",
    "        jd0 = wd.find_element(By.CLASS_NAME, value='show-more-less-html__markup').get_attribute(\"innerHTML\")\n",
    "        print(jd0)\n",
    "\n",
    "        # Selecting elements that hold job 4 criterias \n",
    "        job = wd.find_elements(By.CLASS_NAME, value='description__job-criteria-item')\n",
    "\n",
    "        seniority0 = job[0].find_element(By.CLASS_NAME, value='description__job-criteria-text').text\n",
    "        \n",
    "        emp_type0 = job[1].find_element(By.CLASS_NAME, value='description__job-criteria-text').text\n",
    "        \n",
    "        job_func0 = job[2].find_element(By.CLASS_NAME, value='description__job-criteria-text').text\n",
    "\n",
    "        industries0 = job[3].find_element(By.CLASS_NAME, value='description__job-criteria-text').text\n",
    "\n",
    "        # Adding new information to the existing jobs \n",
    "        jd[CSVtabelIndex] = jd0\n",
    "        seniority[CSVtabelIndex] = seniority0\n",
    "        emp_type[CSVtabelIndex]= emp_type0\n",
    "        job_func[CSVtabelIndex] = job_func0         \n",
    "        industries[CSVtabelIndex] = industries0\n",
    "\n",
    "        CSVtabelIndex = CSVtabelIndex + 1\n",
    "        \n",
    "        time.sleep(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data into DataFrame for further analysis\n",
    "job_data = pd.DataFrame({'ID': job_id,\n",
    "                         'Date': date,\n",
    "                         'Company': company_name,\n",
    "                         'Title': job_title,\n",
    "                         'Location': location,\n",
    "                         'Link': job_link,\n",
    "                         'Description': jd,\n",
    "                         'Level': seniority,\n",
    "                         'Type': emp_type,\n",
    "                         'Function': job_func,\n",
    "                         'Industry': industries\n",
    "                         })\n",
    "\n",
    "job_data.to_csv('linkedin_jobs_data-3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-virtualenv-name",
   "language": "python",
   "name": "my-virtualenv-name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
