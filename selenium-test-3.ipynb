{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup project target, example: Data Science Junior Jobs in Florianopolis\n",
    "url = 'https://www.linkedin.com/jobs/search?keywords=junior%20data%20analyst&location=Florianopolis&refresh=true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 105.0.5195\n",
      "Get LATEST chromedriver version for 105.0.5195 google-chrome\n",
      "Driver [/home/fred/.wdm/drivers/chromedriver/linux64/105.0.5195.52/chromedriver] found in cache\n",
      "/tmp/ipykernel_45406/1428814053.py:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  wd = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    }
   ],
   "source": [
    "# Setup chromedriver \n",
    "try:\n",
    "    wd = webdriver.Chrome()\n",
    "except:\n",
    "    wd = webdriver.Chrome(ChromeDriverManager().install())\n",
    "wd.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n"
     ]
    }
   ],
   "source": [
    "# Get the number of jobs available\n",
    "no_of_jobs = int(wd.find_element(By.CSS_SELECTOR, value='h1>span').get_attribute('innerText'))\n",
    "print(no_of_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Browse all the jobs\n",
    "i = 2\n",
    "while i <= int(no_of_jobs/25)+1: \n",
    "    wd.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "    i = i + 1\n",
    "    try:\n",
    "        wd.find_element(By.XPATH, value='/html/body/main/div/section/button').click()\n",
    "        time.sleep(5)\n",
    "    except:\n",
    "        pass\n",
    "        time.sleep(5)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the jobs\n",
    "job_lists = wd.find_element(By.CLASS_NAME, value='jobs-search__results-list')\n",
    "jobs = job_lists.find_elements(By.TAG_NAME, value='li') # return a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of jobs on the list\n",
    "len(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load job details into dataframe\n",
    "job_id = []\n",
    "job_title = []\n",
    "company_name = []\n",
    "location = []\n",
    "date = []\n",
    "job_link = []\n",
    "jd = []\n",
    "seniority = []\n",
    "emp_type = []\n",
    "job_func = []\n",
    "industries = []\n",
    "\n",
    "for job in jobs:\n",
    "        job_id0 = job.find_element(By.CLASS_NAME, value='base-card').get_attribute('data-entity-urn')\n",
    "        job_id.append(job_id0)\n",
    " \n",
    "        job_title0 = job.find_element(By.CSS_SELECTOR, value='h3').text\n",
    "        job_title.append(job_title0)\n",
    " \n",
    "        company_name0 = job.find_element(By.CSS_SELECTOR, value='h4').text\n",
    "        company_name.append(company_name0)\n",
    " \n",
    "        location0 = job.find_element(By.CLASS_NAME, value='job-search-card__location').text\n",
    "        location.append(location0)\n",
    " \n",
    "        date0 = job.find_element(By.CSS_SELECTOR, value='div>div>time').get_attribute('datetime')\n",
    "        date.append(date0)\n",
    " \n",
    "        job_link0 = job.find_element(By.CSS_SELECTOR, value='a').get_attribute('href')\n",
    "        job_link.append(job_link0) \n",
    "\n",
    "\n",
    "        # Creating the soon to be filled columns of each job\n",
    "        \n",
    "        jd.append(\" \")\n",
    "        seniority.append(\" \")\n",
    "        emp_type.append(\" \")\n",
    "        job_func.append(\" \")\n",
    "        industries.append(\" \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n"
     ]
    }
   ],
   "source": [
    "print(len(jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into DataFrame for further analysis\n",
    "job_data = pd.DataFrame({'ID': job_id,\n",
    "                         'Date': date,\n",
    "                         'Company': company_name,\n",
    "                         'Title': job_title,\n",
    "                         'Location': location,\n",
    "                         'Link': job_link,\n",
    "                         'Description': jd,\n",
    "                         'Level': seniority,\n",
    "                         'Type': emp_type,\n",
    "                         'Function': job_func,\n",
    "                         'Industry': industries\n",
    "                         })\n",
    "\n",
    "# cleaning description column\n",
    "#job_data['Description'] = job_data['Description'].str.replace('\\n', ' ')\n",
    "job_data.to_csv('linkedin_jobs_data-3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently scraped url: https://br.linkedin.com/jobs/view/analista-de-processos-foco-em-analise-de-dados-at-incentiv-me-3272108081?refId=lOGmTxkQVSghHlJwLMxneg%3D%3D&trackingId=a%2FVx6RPH%2BTlx2xCoo%2BXxcQ%3D%3D&position=1&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "Como Analista de Processos Pleno voc√™ ter√° a miss√£o de contribuir para implementa√ß√£o e manuten√ß√£o do sistema de gest√£o de processos de neg√≥cios e qualidade transformando as fontes de dados em informa√ß√µes, facilitando a tomada de decis√£o dos gestores da empresa, garantindo a ader√™ncia aos par√¢metros das normas e exig√™ncias do mercado, dentro das pol√≠ticas definidas pela empresa.\n",
      "\n",
      "\n",
      "\n",
      "Nesse sentido precisamos que voc√™ tenha um perfil anal√≠tico, comunicativo, bom racioc√≠nio l√≥gico e que tenha muita proatividade para solucionar os problemas que possam surgir durante a jornada. Se identificou.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aqui voc√™ encontrar√° gente do bem, positiva, que ama o que faz e que faz acontecer!\n",
      "\n",
      "Gente que acredita na riqueza da diversidade, por isso todas as nossas vagas s√£o trabalhadas pensando em promover e valorizar uma cultura inclusiva que busque a equidade em rela√ß√£o a G√™nero, LGBTQI+, Pessoas com Defici√™ncia, Etnia e Regionalidades.\n",
      "\n",
      "A nossa hist√≥ria est√° s√≥ come√ßando e n√≥s sonhamos grande!\n",
      "\n",
      "E a√≠, bora fazer parte desse time? üíú\n",
      "Not Applicable\n",
      "Full-time\n",
      "Management and Manufacturing\n",
      "IT Services and IT Consulting\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Load further details\n",
    "\n",
    "filename = 'linkedin_jobs_data-3.csv'\n",
    "\n",
    "# Opening csv file to read job links\n",
    "\n",
    "with open(filename, 'r') as csvfile: \n",
    "    csvreader = csv.reader(csvfile)\n",
    "    next(csvreader)\n",
    "\n",
    "    for job in csvreader:\n",
    "        # indicates which job is going to be updated\n",
    "        CSVtabelIndex = 0\n",
    "\n",
    "        url = job[5]\n",
    "        print(\"Currently scraped url:\",url)\n",
    "        wd.get(url)\n",
    "\n",
    "        # selecting elements that hold the job description (about)\n",
    "        jd0 = wd.find_element(By.CLASS_NAME, value='show-more-less-html__markup').text\n",
    "        print(jd0)\n",
    "        \n",
    "        # selecting elements that hold job 4 criterias \n",
    "        job = wd.find_elements(By.CLASS_NAME, value='description__job-criteria-item')\n",
    "\n",
    "        seniority0 = job[0].find_element(By.CLASS_NAME, value='description__job-criteria-text').text\n",
    "        print(seniority0)\n",
    "        \n",
    "        emp_type0 = job[1].find_element(By.CLASS_NAME, value='description__job-criteria-text').text\n",
    "        print(emp_type0)\n",
    "        \n",
    "        job_func0 = job[2].find_element(By.CLASS_NAME, value='description__job-criteria-text').text\n",
    "        print(job_func0)\n",
    "\n",
    "        industries0 = job[3].find_element(By.CLASS_NAME, value='description__job-criteria-text').text\n",
    "        print(industries0)\n",
    "\n",
    "\n",
    "        jd[CSVtabelIndex] = jd0\n",
    "        seniority[CSVtabelIndex] = seniority0\n",
    "        emp_type[CSVtabelIndex]= emp_type0\n",
    "        job_func[CSVtabelIndex] = job_func0         \n",
    "        industries[CSVtabelIndex] = industries0\n",
    "\n",
    "        CSVtabelIndex = CSVtabelIndex + 1\n",
    "        break\n",
    "        time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124 124 124 124 124 124 124 124 124 124 124\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(len(job_id),len(date),len(company_name),len(job_title),len(location),len(job_link),len(jd),len(seniority),len(emp_type),len(job_func),len(industries))\n",
    "\n",
    "#Load data into DataFrame for further analysis\n",
    "job_data = pd.DataFrame({'ID': job_id,\n",
    "                         'Date': date,\n",
    "                         'Company': company_name,\n",
    "                         'Title': job_title,\n",
    "                         'Location': location,\n",
    "                         'Link': job_link,\n",
    "                         'Description': jd,\n",
    "                         'Level': seniority,\n",
    "                         'Type': emp_type,\n",
    "                         'Function': job_func,\n",
    "                         'Industry': industries\n",
    "                         })\n",
    "\n",
    "job_data.to_csv('linkedin_jobs_data-3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
