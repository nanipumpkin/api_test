{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL that generates the initial CSV list:  https://www.linkedin.com/jobs/search?keywords=junior%20data%20analyst&location=Florianopolis&refresh=true\n"
     ]
    }
   ],
   "source": [
    "# Setup project target, example: Data Science Junior Jobs in Florianopolis\n",
    "url = 'https://www.linkedin.com/jobs/search?keywords=junior%20data%20analyst&location=Florianopolis&refresh=true'\n",
    "print(\"URL that generates the initial CSV list: \", url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29990/1741417621.py:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  wd = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    }
   ],
   "source": [
    "# Setup chromedriver \n",
    "try:\n",
    "    wd = webdriver.Chrome()\n",
    "except:\n",
    "    wd = webdriver.Chrome(ChromeDriverManager().install())\n",
    "wd.get(url)\n",
    "\n",
    "# Loop verifying if a redirect has occurred and then undoes it.\n",
    "while 'authwall' in wd.current_url:\n",
    "    print(wd.current_url)\n",
    "    time.sleep(1)\n",
    "    wd.get(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs found:  218\n"
     ]
    }
   ],
   "source": [
    "# Get the number of jobs available\n",
    "no_of_jobs = int(wd.find_element(By.CSS_SELECTOR, value='h1>span').get_attribute('innerText'))\n",
    "print(\"Number of jobs found: \",no_of_jobs-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Browse all the jobs\n",
    "i = 2\n",
    "while i <= int(no_of_jobs/25)+1: \n",
    "    wd.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "    i = i + 1\n",
    "    try:\n",
    "        wd.find_element(By.XPATH, value='/html/body/div[1]/div/main/section[2]/button').click()\n",
    "        time.sleep(5)\n",
    "    except:\n",
    "        pass\n",
    "        time.sleep(5)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the jobs\n",
    "job_lists = wd.find_element(By.CLASS_NAME, value='jobs-search__results-list')\n",
    "jobs = job_lists.find_elements(By.TAG_NAME, value='li') # return a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalizing job details into dataframe\n",
    "job_id = []\n",
    "job_title = []\n",
    "company_name = []\n",
    "location = []\n",
    "date = []\n",
    "job_link = []\n",
    "jd = []\n",
    "seniority = []\n",
    "emp_type = []\n",
    "job_func = []\n",
    "industries = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading job details into dataframe\n",
    "for job in jobs:\n",
    "        job_id0 = job.find_element(By.CLASS_NAME, value='base-card').get_attribute('data-entity-urn')\n",
    "        job_id.append(job_id0)\n",
    " \n",
    "        job_title0 = job.find_element(By.CSS_SELECTOR, value='h3').text\n",
    "        job_title.append(job_title0)\n",
    " \n",
    "        company_name0 = job.find_element(By.CSS_SELECTOR, value='h4').text\n",
    "        company_name.append(company_name0)\n",
    " \n",
    "        location0 = job.find_element(By.CLASS_NAME, value='job-search-card__location').text\n",
    "        location.append(location0)\n",
    " \n",
    "        date0 = job.find_element(By.CSS_SELECTOR, value='div>div>time').get_attribute('datetime')\n",
    "        date.append(date0)\n",
    " \n",
    "        job_link0 = job.find_element(By.CSS_SELECTOR, value='a').get_attribute('href')\n",
    "        job_link.append(job_link0) \n",
    "\n",
    "\n",
    "        # Creating the soon to be filled columns of each job\n",
    "        \n",
    "        jd.append(\" \")\n",
    "        seniority.append(\" \")\n",
    "        emp_type.append(\" \")\n",
    "        job_func.append(\" \")\n",
    "        industries.append(\" \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extracted job listing links:  220\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of extracted job listing links: \",len(jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into DataFrame for further analysis\n",
    "job_data = pd.DataFrame({'ID': job_id,\n",
    "                         'Date': date,\n",
    "                         'Company': company_name,\n",
    "                         'Title': job_title,\n",
    "                         'Location': location,\n",
    "                         'Link': job_link,\n",
    "                         'Description': jd,\n",
    "                         'Level': seniority,\n",
    "                         'Type': emp_type,\n",
    "                         'Function': job_func,\n",
    "                         'Industry': industries\n",
    "                         })\n",
    "job_data.to_csv('linkedin_jobs_data-3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Scraped Url:\n",
      " https://br.linkedin.com/jobs/view/analista-de-processos-foco-em-analise-de-dados-at-incentiv-me-3272108081?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=fDC%2BEqFkaEXoPx9JoEAyMg%3D%3D&position=1&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "DEBUG:  https://br.linkedin.com/jobs/view/analista-de-processos-foco-em-analise-de-dados-at-incentiv-me-3272108081?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=fDC%2BEqFkaEXoPx9JoEAyMg%3D%3D&position=1&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "\n",
      "        Como Analista de Processos Pleno você terá a missão de contribuir para implementação e manutenção do sistema de gestão de processos de negócios e qualidade transformando as fontes de dados em informações, facilitando a tomada de decisão dos gestores da empresa, garantindo a aderência aos parâmetros das normas e exigências do mercado, dentro das políticas definidas pela empresa.<br><br><strong><u>Então Se Liga<br><br></u></strong>Nesse sentido precisamos que você tenha um perfil analítico, comunicativo, bom raciocínio lógico e que tenha muita proatividade para solucionar os problemas que possam surgir durante a jornada. Se identificou.<br><br><strong>Responsabilidades e atribuições<br><br></strong><strong><u>Suas Principais Responsabilidades Serão<br></u></strong><ul><li>Definir padrões de coleta, armazenamento, tratamento, análise e aplicação de dados essenciais para organização;</li><li>Orientar os departamentos na elaboração e manutenção de Métricas, Indicadores de desempenho de processos, Acordos de Nível de serviço (ANS) e Acordos de nível Operacional ( ANO) , conforme os padrões estabelecidos;</li><li>Elaborar dashboards voltados ao gerenciamento diário e gestão de desempenho. </li><li>Acompanhar o desempenho dos indicadores, realizar análise crítica e gerenciar os planos de melhoria, conforme os padrões estabelecidos;</li><li>Identificar oportunidades, desenhar e conduzir implementações de melhorias nos processos e seus indicadores ;</li><li>Garantir a elaboração, manutenção ( atualização, codificação, controle de versões, vencimento) da documentação dos processos da empresa conforme os padrões estabelecidos;</li><li>Contribuir com a elaboração do plano anual das atividades relacionadas com o sistema de gerenciamento de processos;</li><li>Aplicar ferramentas de resolução de problemas conforme os padrões estabelecidos; </li><li>Realizar mapeamento de processos da empresa conforme os padrões estabelecidos ( ferramentas, notação);</li><li>Realizar entrevistas, reuniões e treinamentos envolvendo grupos específicos e/ou todos os colaboradores, visando a multiplicação dos conhecimentos e facilitando a implementação do gerenciamento de processos;</li><li>Divulgar a metodologia de gerenciamento de processos e indicadores de desempenho da empresa, através da preparação e distribuição de material sobre o assunto, organização de cursos e palestras, programas especiais de divulgação, visando a conscientização e envolvimento de todas as áreas da empresa;</li><li>Fortalecer a visão sistêmica e a interrelação entre processos, promovendo a conscientização das pessoas e setores diretamente envolvidos, visando o seu engajamento e sinergia na busca pela melhoria contínua. <br></li></ul><strong>Requisitos e qualificações<br><br></strong><strong><u>Requisitos<br></u></strong><ul><li>Formação em Engenharia, Administração ou afins;</li><li>Conhecimento em gerenciamento de desempenho dos processos e experiência na implementação de gestão por indicadores de desempenho;</li><li>Conhecimento em ferramentas de avaliação e visualização de dados (Power BI)</li><li>Conhecimento avançado em ferramentas voltadas a criação de tabelas, controles, cálculos ( Google Planilhas) </li><li>Conhecimento do padrão ( notação) e de ferramentas para mapeamento /desenho de processos - Bizagi</li><li>Conhecimento em gestão documental de processos;</li><li>Conhecimento de ferramentas voltadas a resolução de problemas ;</li><li>Conhecimento das melhores práticas em gerenciamento de processos; </li><li>Conhecimento em gerenciamento de desempenho dos processos;</li><li>Entendimento da amplitude e importância dos conceitos e aspectos referentes a gerenciamento de processos;</li><li>Conhecimento avançado de google drive.<br></li></ul><strong><u>Será Um Diferencial Se Você Tiver<br></u></strong><ul><li>Experiência na área de tecnologia e startups;</li><li>Conhecimento em metodologia ágil.</li><li>Conhecimento Filosofia Lean<br></li></ul><strong>Habilidades e Atitudes <br></strong><ul><li>Administração do tempo </li><li>Capacidade de decisão </li><li>Comunicação </li><li>Controle emocional </li><li>Diligência </li><li>Espírito crítico </li><li>Imparcialidade </li><li>Liderança </li><li>Planejamento e controle </li><li>Proatividade </li><li>Relacionamento interpessoal </li><li>Utilização de raciocínio lógico </li><li>Visão estratégica<br></li></ul><strong>Informações adicionais<br><br></strong>Aqui você encontrará gente do bem, positiva, que ama o que faz e que faz acontecer!<br><br>Gente que acredita na riqueza da diversidade, por isso todas as nossas vagas são trabalhadas pensando em promover e valorizar uma cultura inclusiva que busque a equidade em relação a Gênero, LGBTQI+, Pessoas com Deficiência, Etnia e Regionalidades.<br><br>A nossa história está só começando e nós sonhamos grande!<br><br>E aí, bora fazer parte desse time? 💜\n",
      "      \n",
      "Current Scraped Url:\n",
      " https://br.linkedin.com/jobs/view/sales-operations-sales-data-analyst-at-fiberx-3283612343?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=Qdgb7HAnQy7YOjV7pu4Kxw%3D%3D&position=2&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "DEBUG:  https://br.linkedin.com/jobs/view/sales-operations-sales-data-analyst-at-fiberx-3283612343?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=Qdgb7HAnQy7YOjV7pu4Kxw%3D%3D&position=2&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "\n",
      "        A FiberX está com posição para Sales Operation no nosso time de Projetos.<p><br></p>Se você é uma pessoa organizada, comprometida tem conhecimento em análise de dados e acompanhamento de KPI's da área comercial, essa oportunidade pode ser sua.<p><br></p><strong><u>Atribuições Da Vaga</u></strong><p><br></p><ul><li>Identificar melhorias e automatização dos processos de vendas tornando ornar os processos mais eficazes e produtivos.</li><li>Avaliar as metodologias de vendas;</li><li>Definir com os times os forecast de vendas;</li><li>Análise de dados;</li><li>Identificar e acompanhar métricas, KPIs e metas de vendas;</li><li>Criação de relatórios e dashboards;</li><li>Acompanhamento do processo de vendas;</li><li>Mapeamento e desenho do processo de vendas de projetos complexos;</li><li>Identificar melhorias nos processos e funis de vendas;</li><li>Criação de apresentações executivas em português e inglês;</li><li>Acompanhamento de follow ups de projetos.</li></ul><p><br></p><strong><u>Requisitos</u></strong><p><br></p><ul><li>Graduação em Administração, Economia, Engenharias e afins;</li><li>KPI's;</li><li>Sales processes analysis;</li><li>Pipeline Review;</li><li>CRM automation;</li><li>BI Reports;</li><li>Sales frameworks;</li><li>Sales Operations;</li><li>Data Analytics;</li><li>Business Intelligence;</li><li>Excel Avançado;</li><li>Inglês avançado</li></ul><p><br></p><strong><u>Benefícios</u></strong><p><br></p><ul><li>Vale alimentação;</li><li>Seguro de Vida em grupo;</li><li>Plano de Saúde;</li><li>Bolsa Graduação ou Pós-graduação;</li><li>Bolsa Idiomas;</li><li>Cultura de Inovação;</li><li>Ambiente de aprendizagem.</li></ul><p><br></p>Quer fazer parte desse time que só cresce? Participe do nosso processo seletivo, nós queremos te conhecer.\n",
      "      \n",
      "Current Scraped Url:\n",
      " https://br.linkedin.com/jobs/view/analista-de-processos-foco-em-analise-de-dados-at-incentiv-3288728174?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=Fb2p0RlDNqka%2BGs1fGbWxQ%3D%3D&position=3&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "DEBUG:  https://br.linkedin.com/jobs/view/analista-de-processos-foco-em-analise-de-dados-at-incentiv-3288728174?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=Fb2p0RlDNqka%2BGs1fGbWxQ%3D%3D&position=3&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "\n",
      "        Atuará nas atividades internas e demais funções pertinentes ao cargo. Necessário Conhecimento na área de atuação.<br><br><strong><u>Beneficios<br><br></u></strong><strong>Formação Acadêmica:<br><br></strong>Não informado<br><br><strong><u>Salário<br><br></u></strong><strong>Experiência:<br><br></strong>A combinar<br><br><strong><u>Cargo<br><br></u></strong>Analista de processos<br><br><strong><u>Empresa<br><br></u></strong>INCENTIV<br><br>Consultoria em publicidade, agências de publicidade Agenciamento de espaços para publicidade, exceto em veículos de comunicação e Marketing direto Consultoria em publicidade.<br><br><strong><u>Ramo<br><br></u></strong>Publicidade/ Propaganda\n",
      "      \n",
      "Current Scraped Url:\n",
      " https://br.linkedin.com/jobs/view/analista-de-dados-at-seazone-3273971302?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=dlOlEUQ01jKeDW3VvRBOKA%3D%3D&position=4&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "DEBUG:  https://br.linkedin.com/jobs/view/analista-de-dados-at-seazone-3273971302?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=dlOlEUQ01jKeDW3VvRBOKA%3D%3D&position=4&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "\n",
      "        <strong>Como será um dia de trabalho típico na Seazone?<br><br></strong>Fazer parte dessa equipe significa que você ajudará a compor um time de excelência para trabalhar internamente na Seazone.<br><br><strong>O que estamos procurando exatamente?<br><br></strong>De modo geral, procuramos algumas características básicas e uma delas é trazer para trabalhar conosco pessoas que gostem de aprender, que tenham iniciativa, autonomia e vontade de fazer o melhor pelos nossos clientes.<br><br><strong>Responsabilidades e atribuições<br></strong><ul><li>Análise de dados</li><li>Geração de relatórios</li><li>Criação de dashboards</li><li>Criação de banco de dados﻿<br></li></ul><strong>Requisitos e qualificações<br></strong><ul><li>Pensamento analítico</li><li>Excel intermediário</li><li>Conhecimento em Power BI ou equivalente<br></li></ul><strong>Informações adicionais<br><br></strong><strong><u>Diferenciais<br></u></strong><ul><li>Excel avançado</li><li>Conhecimento em Python e SQL<br></li></ul><strong><u>﻿Benefícios<br></u></strong><ul><li>Horário flexível;</li><li>Day-off in birthday;</li><li>Help Tele-Medicina.<br></li></ul><strong><u>Parcerias<br></u></strong><ul><li>Gogood para você e seus dependentes;</li><li>CCLI idiomas.</li></ul>\n",
      "      \n",
      "Current Scraped Url:\n",
      " https://br.linkedin.com/jobs/view/analista-de-dados-cresol-confedera%C3%A7%C3%A3o-at-cresol-cooperativa-3247509325?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=uAjcICqP4ECM9p3v9Iogcg%3D%3D&position=5&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "DEBUG:  https://br.linkedin.com/jobs/view/analista-de-dados-cresol-confedera%C3%A7%C3%A3o-at-cresol-cooperativa-3247509325?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=uAjcICqP4ECM9p3v9Iogcg%3D%3D&position=5&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "\n",
      "        Estamos em busca de um <strong>Analista de Dados</strong> para somar no nosso time!<br><br>Buscamos profissionais com propósito, que sonham grande e que acreditam na força da Cooperação!<br><br>Nossa cultura é focada em um ambiente inclusivo, diverso e colaborativo, permitindo que as pessoas possam ser elas mesmas! Juntos, construímos valores que são aplicados em nosso dia a dia, no relacionamento com cada cooperado, com o compromisso de tornar a Cresol cada vez mais forte!<br><br>Vem ser Cresol você também!<br><br><strong>Responsabilidades e atribuições<br></strong><ul><li>Desenhar e implementar processos de ETL;</li><li>Enriquecer as fontes de dados publicadas na plataforma de B.I. para garantir a qualidade das mesmas bem como das visualizações desenvolvidas;</li><li>Atuar no apoio à limpeza, enriquecimento, modelagem e transformação dos dados, utilizando fontes de dados já existentes, ou fontes de dados externas;</li><li>Auxiliar tecnicamente os times quando ocorrerem dúvidas sobre os dados e o funcionamento das integrações, fontes de dados e visualizações.<br></li></ul><strong>Requisitos e qualificações<br></strong><ul><li>Ensino superior em andamento em Sistema de Informação, Análise de Dados, Computação, Contabilidade, matemática, estatística ou áreas afins,</li><li>Vivência em Bancos de Dados; </li><li>Pensamento lógico, exploratório e investigativo; </li><li>Metodologias ágeis;</li><li>Vivência com engenharia de dados;</li><li>Conhecer conceitos do mercado de instituições financeiras (Bancos ou Cooperativas por exemplo); </li><li>Vivência com desenvolvimento de scripts em alguma linguagem (por exemplo Python); </li><li>Ter trabalhado com grandes volumes de dados; </li><li>Experiência com criação e manutenção de consultas SQL. </li><li>Ambiente Cloud.<br></li></ul><strong>Informações adicionais<br><br></strong><strong><u>Benefícios<br></u></strong><ul><li>Vale Alimentação e/ou Refeição – para comprar seu alimento e aproveitar do seu jeito;</li><li>Seguro de Vida - um cuidado a mais que também pode ser acionado em casos de Doenças Graves e Auxílio Funeral, aquela ajuda na hora que mais precisamos;</li><li>Plano de Saúde - a mensalidade é um presente da Cresol para o colaborador, estamos sempre juntos;</li><li>Plano Odontológico - a mensalidade é um presente da Cresol para o colaborador;</li><li>Previdência Privada - a Cresol se preocupa com seu futuro;</li><li>PPR (Programa de Participação nos Resultados) – conquistamos juntos e celebramos juntos; </li><li>Cartão Natal – a Cresol fornece um cartão no Natal no final do ano, assim a ceia é do jeito que o colaborador gosta;</li><li>Auxílio Creche - a Cresol cuida também do bem estar dos filhos dos colaboradores; </li><li>Desenvolvimento – a Cresol acredita no desenvolvimento dos colaboradores e investe nele durante o ano; </li><li>Cresol Acolhe – para o colaborador e sua Família, aqui oferecemos desde suporte a dúvidas jurídicas como dicas para seu Pet, por meio de ligações de qualquer lugar do Brasil;</li><li>Gympass - Acesso a academias físicas e aulas de Yoga, Meditação e Funcional ao vivo, um benefício completo para o seu Bem Estar.</li></ul>\n",
      "      \n",
      "Current Scraped Url:\n",
      " https://br.linkedin.com/jobs/view/analista-de-dados-cresol-confedera%C3%A7%C3%A3o-at-cresol-cooperativa-3247510275?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=kePvdOyCaUudr55wqh%2FARA%3D%3D&position=6&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "DEBUG:  https://br.linkedin.com/jobs/view/analista-de-dados-cresol-confedera%C3%A7%C3%A3o-at-cresol-cooperativa-3247510275?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=kePvdOyCaUudr55wqh%2FARA%3D%3D&position=6&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "\n",
      "        Estamos em busca de um <strong>Analista de Dados</strong> para somar no nosso time!<br><br>Buscamos profissionais com propósito, que sonham grande e que acreditam na força da Cooperação!<br><br>Nossa cultura é focada em um ambiente inclusivo, diverso e colaborativo, permitindo que as pessoas possam ser elas mesmas! Juntos, construímos valores que são aplicados em nosso dia a dia, no relacionamento com cada cooperado, com o compromisso de tornar a Cresol cada vez mais forte!<br><br>Vem ser Cresol você também!<br><br><strong>Responsabilidades e atribuições<br></strong><ul><li>Realizar as atividades inerentes à análise e correção de dados, dimensionando requisitos, providenciando a coleta e extração de dados, realizando a análise, monitoramento e correção de dados, com o objetivo de garantir a disponibilização de dados e informações precisas para execução dos processos e para a tomada de decisões;</li><li>Desenhar e implementar processos de ETL;</li><li>Enriquecer as fontes de dados publicadas na plataforma de B.I. para garantir a qualidade das mesmas bem como das visualizações desenvolvidas;</li><li>Atuar no apoio à limpeza, enriquecimento, modelagem e transformação dos dados, utilizando fontes de dados já existentes, ou fontes de dados externas;</li><li>Auxiliar tecnicamente os times quando ocorrerem dúvidas sobre os dados e o funcionamento das integrações, fontes de dados e visualizações.<br></li></ul><strong>Requisitos e qualificações<br></strong><ul><li>Ensino superior em andamento em Sistema de Informação, Análise de Dados, Computação, Contabilidade, matemática, estatística ou áreas afins,</li><li>Vivência em Bancos de Dados; </li><li>Pensamento lógico, exploratório e investigativo; </li><li>Metodologias ágeis;</li><li>Vivência com engenharia de dados;</li><li>Conhecer conceitos do mercado de instituições financeiras (Bancos ou Cooperativas por exemplo); </li><li>Vivência com desenvolvimento de scripts em alguma linguagem (por exemplo Python); </li><li>Ter trabalhado com grandes volumes de dados; </li><li>Experiência com criação e manutenção de consultas SQL;</li><li>Ambiente Cloud.<br></li></ul><strong>Informações adicionais<br><br></strong><strong><u>Benefícios<br></u></strong><ul><li>Vale Alimentação e/ou Refeição – para comprar seu alimento e aproveitar do seu jeito;</li><li>Seguro de Vida - um cuidado a mais que também pode ser acionado em casos de Doenças Graves e Auxílio Funeral, aquela ajuda na hora que mais precisamos;</li><li>Plano de Saúde - a mensalidade é um presente da Cresol para o colaborador, estamos sempre juntos;</li><li>Plano Odontológico - a mensalidade é um presente da Cresol para o colaborador;</li><li>Previdência Privada - a Cresol se preocupa com seu futuro;</li><li>PPR (Programa de Participação nos Resultados) – conquistamos juntos e celebramos juntos; </li><li>Cartão Natal – a Cresol fornece um cartão no Natal no final do ano, assim a ceia é do jeito que o colaborador gosta;</li><li>Auxílio Creche - a Cresol cuida também do bem estar dos filhos dos colaboradores; </li><li>Desenvolvimento – a Cresol acredita no desenvolvimento dos colaboradores e investe nele durante o ano; </li><li>Cresol Acolhe – para o colaborador e sua Família, aqui oferecemos desde suporte a dúvidas jurídicas como dicas para seu Pet, por meio de ligações de qualquer lugar do Brasil;</li><li>Gympass - Acesso a academias físicas e aulas de Yoga, Meditação e Funcional ao vivo, um benefício completo para o seu Bem Estar.</li></ul>\n",
      "      \n",
      "Current Scraped Url:\n",
      " https://br.linkedin.com/jobs/view/analista-de-dados-at-dynamox-3269138473?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=gYQRjl9XHaqOcOx6%2Bm%2FSUA%3D%3D&position=7&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "DEBUG:  https://br.linkedin.com/jobs/view/analista-de-dados-at-dynamox-3269138473?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=gYQRjl9XHaqOcOx6%2Bm%2FSUA%3D%3D&position=7&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "\n",
      "        Sobre nós:<p><br></p>A DYNAMOX é uma empresa de alta tecnologia que desenvolve sistemas de monitoramento e aquisição de dados de vibração e temperatura. Especialista em análise de vibrações e monitoramento da condição de ativos industriais. Solução ideal para a manutenção preditiva. A Dynamox conta com um departamento de P&amp;D que desenvolve sistemas completos: hardware ao software industrial.<p><br></p>Somos excelência no que fazemos: empresa certificada ISO 9001, 27001 e Great Place to Work!<p><br></p>Se identificou? Então vem fazer parte do nosso DynaTeam!<p><br></p>O que estamos buscando:<p><br></p>Pessoa responsável por desenvolver e implementar análises de dados, geração de relatórios e outras estratégias com foco no aumento da performance e escalabilidade do produto, com impacto na melhoria da experiência dos clientes.<p><br></p>Responsabilidades e atribuições:<p><br></p><ul><li>Gerar métricas e monitorar indicadores da aderência dos usuários e da performance da solução;</li><li>Validar a experiência do cliente quanto à usabilidade e ao desempenho do produto;</li><li>Identificar e discutir pontos de melhoria dos produtos com times de desenvolvimento;</li><li>Reunir-se com representantes comerciais e clientes para definição de escopo de ferramentas e investigação de problemas;</li><li>Extrair e transformar dados de bancos de dados e logs de sistema para criação de relatórios de indicadores, bases de dados e apresentações;</li><li>Seguir planejamento para desenvolvimento e manutenção de algoritmos de automação e ferramentas;</li><li>Organizar e executar testes de validação de novas features, protótipos e produtos;</li><li>Produzir documentações, disseminar padrões e difundir informações técnicas acerca dos produtos;</li><li>Contribuir e disseminar práticas de segurança de informação e privacidade de dados confidenciais e restritos, no que diz respeito às rotinas do departamento e empresa.</li></ul><p><br></p>Requisitos e Qualificações:<p><br></p><ul><li>Perfil analítico, comunicador e solucionador;</li><li>Experiência acadêmica ou profissional em análise de dados;</li><li>Conhecimento em lógicas e linguagens de programação - desejável Python;</li><li>Inglês técnico, desejável espanhol.</li></ul><p><br></p>Formação:<p><br></p><ul><li>Ensino superior completo em Engenharias, Automação Industrial, Ciências da Computação, Sistemas de Informação ou áreas correlatas.</li></ul><p><br></p>Será um diferencial se:<p><br></p><ul><li>Será um diferencial se tiver experiência com gestão de projetos e/ou liderança de equipes;</li><li>Será um diferencial se tiver experiência com ferramentas de Business Intelligence (PowerBI, Datastudio e afins);</li><li>Será um diferencial se tiver experiência com ferramentas de Gestão de Desenvolvimento (Jira, Git e afins);</li><li>Será um diferencial se tiver noções de eletrônica, telecomunicações, redes de computadores ou ativos industriais;</li><li>Será um diferencial se tiver noções de operações de streaming de dados (Kafka), de bancos de dados (Mongo, Big Query) e/ou integrações de dados (APIs).</li></ul><p><br></p>Benefícios:<p><br></p><ul><li>Vale transporte OU Auxílio deslocamentos sem desconto em folha;</li><li>Vale alimentação/refeição flexível sem desconto em folha;</li><li>Seguro de vida global;</li><li>Plano de saúde custeado pela empresa após o período de experiência;</li><li>Plano odontológico custeado pela empresa após o período de experiência;</li><li>Convênio com Farmasesi e OdontoSesi;</li><li>Convênio GoGood - Plataforma de bem-estar;</li><li>Atendimento com fisioterapeuta/osteopata na empresa;</li><li>Sala de descompressão com puffs, jogos e videogames;</li><li>Frutas e café à vontade;</li><li>No dress code;</li><li>A vista de nosso escritório é incrível! Empresa situada no parque tecnológico de Florianópolis.</li></ul><p><br></p>VAGA PRESENCIAL - CLT - 44h\n",
      "      \n",
      "Current Scraped Url:\n",
      " https://br.linkedin.com/jobs/view/engenheira-o-de-dados-j%C3%BAnior-remoto-at-bix-tecnologia-consultoria-de-dados-3247489068?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=KILiqr0AFwy62lZMX5b6Ww%3D%3D&position=8&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "DEBUG:  https://www.linkedin.com/authwall?trk=qf&original_referer=&sessionRedirect=https%3A%2F%2Fbr.linkedin.com%2Fjobs%2Fview%2Fengenheira-o-de-dados-j%25C3%25BAnior-remoto-at-bix-tecnologia-consultoria-de-dados-3247489068%3FrefId%3DM3gvRWmiPk9RfbiFbr9yRA%253D%253D%26trackingId%3DKILiqr0AFwy62lZMX5b6Ww%253D%253D%26position%3D8%26pageNum%3D0%26trk%3Dpublic_jobs_jserp-result_search-card\n",
      "https://www.linkedin.com/authwall?trk=qf&original_referer=&sessionRedirect=https%3A%2F%2Fbr.linkedin.com%2Fjobs%2Fview%2Fengenheira-o-de-dados-j%25C3%25BAnior-remoto-at-bix-tecnologia-consultoria-de-dados-3247489068%3FrefId%3DM3gvRWmiPk9RfbiFbr9yRA%253D%253D%26trackingId%3DKILiqr0AFwy62lZMX5b6Ww%253D%253D%26position%3D8%26pageNum%3D0%26trk%3Dpublic_jobs_jserp-result_search-card\n",
      "\n",
      "        Somos uma empresa apaixonada por pessoas, pautamos sempre pela qualidade das nossas relações e pelo cuidado com cada membro do time. Estamos buscando uma pessoa para fazer parte deste time que vem crescendo a cada dia, tanto em número quanto em desenvolvimento.<br><br>Encorajamos e acreditamos no nosso time e prezamos por fazer junto. Se você é essa pessoa, que tem um senso de equipe e que procura por desenvolvimento constante, a BIX é para você!<br><br>Vem fazer parte da BIX Tecnologia!<br><br>O que esperamos ver em você:<br><ul><li>Comunicação e Relacionamento Interpessoal;</li><li>Resolução de Problemas;</li><li>Interesse e Capacidade de Aprendizagem;</li><li>Gestão do Tempo e Planejamento;</li><li>Capacidade Analítica.<br></li></ul>O que esperamos que você tenha:<br><ul><li>Experiência em Python, Java ou Scala;</li><li>Conhecimento avançado em SQL;</li><li>Conhecimento em Git e versionamento de código;</li><li>Ensino Superior cursando ou completo, em áreas correlatas a sua função: engenharias, cursos de computação e cursos relacionados à área de exatas.<br></li></ul>O que você fará em seu dia a dia:<br><ul><li>Criar pipelines de dados, utilizando python e sql, para ingerir e transformar dados para o time de negócio, sempre que existir demanda;</li><li>Orquestrar pipelines, utilizando Apache Airflow, para sequenciar e automatizar tarefas a cada novo pipeline desenvolvido;</li><li>Armazenar dados em Data Lakes, utilizando AWS S3, Google Cloud Storage ou Azure Data Lake Storage Gen2, sempre que houver uma solicitação do cliente;</li><li>Realizar reuniões com clientes, por meio de videoconferência, desenvolvendo os questionamentos estratégicos voltados ao seu negócio/processo, a cada início de projeto ou sprint;</li><li>Criar e manter a documentação do sistema, utilizando Notion, para ajudar na gestão de conhecimento, a cada novo projeto.<br></li></ul>O que a BIX oferece para você:<br><ul><li>Cartão de benefícios flexíveis;</li><li>Plataforma de terapia e nutricionistas online;</li><li>Plano de saúde e Odontológico;</li><li>Plano de carreira acelerado;</li><li>Participação nos resultados;</li><li>Contato direto com líderes de grandes empresas;</li><li>Ambiente diferenciado (Hora BIX, integrações e Happy Hours, Programa de Mentoria, Reuniões 1on1);</li><li>Aulas on-line de inglês (cambly);</li><li>Folga no aniversário;</li><li>Trabalho remoto.<br></li></ul>Em caso de dúvidas, entrar em contato por e-mail: talentos@bixtecnologia.com.br.\n",
      "      \n",
      "Current Scraped Url:\n",
      " https://br.linkedin.com/jobs/view/analista-de-dados-at-3neuron-3255755934?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=1mTH8xfNBrnCrIpRbyi9Cw%3D%3D&position=9&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "DEBUG:  https://br.linkedin.com/jobs/view/analista-de-dados-at-3neuron-3255755934?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=1mTH8xfNBrnCrIpRbyi9Cw%3D%3D&position=9&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "\n",
      "        Quer se juntar a um time de profissionais com vivência multidisciplinar nas mais diversas áreas de conhecimento em um ambiente de alto desempenho?<p><br></p><strong>Venha para 3NEURON!</strong><p><br></p>Estamos buscando candidatos que abracem desafios de transformação digital e análise de dados. Se você deseja crescer junto com a gente, não perca tempo! Inscreva-se no processo seletivo!<p><br></p><strong>REQUISITOS</strong><p><br></p><ul><li>Boa comunicação visando o mapeamento de requisitos e apresentação das soluções desenvolvidas;</li><li>Conhecimento em Metodologias desenvolvimento lean/agile;</li><li>Conhecimento em Data Modeling;</li><li>Conhecimento em Plataformas de Nuvem do mercado (Amazon Web Services, Google Cloud e Microsoft Azure);</li><li>Experiência com soluções para construção dos processos de ETL;</li><li>Conhecimento em Linguagens de programação (SQL, Shell Script, R, Pyhton, Scala, Java, etc.);</li><li>Experiência no desenvolvimento de Dashboards com Microsoft Power BI.</li></ul><p><br></p><strong>ATIVIDADES</strong><p><br></p><ul><li>Atuar no planejamento de projetos para dimensionamento da infraestrutura de BI e modelos de dados junto aos clientes;</li><li>Trabalhar com os consultores e analistas de negócios para alinhamento com as estratégias e objetivos de negócio;</li><li>Extrair os dados de diversas fontes de dados para ingestão nas plataformas de análise de dados;</li><li>Assegurar que os dados sejam apropriados, acessíveis e disponíveis;</li><li>Construir dashboards para visualização de dados;</li><li>Prover a manutenção e a disponibilidade da solução de BI;</li><li>Otimizar a performance e escalabilidade;</li><li>Identificar oportunidades para aquisição de dados.</li></ul><p><br></p><strong>BENEFÍCIOS</strong><p><br></p><ul><li>Desenvolvimento profissional em projetos de diversas área e segmentos;</li><li>Incentivo às certificações;</li><li>Participação do Programa de Formação de Consultores 3ENURON e acesso aos materiais da Universidade 3NEURON;</li><li>Avaliação de Desempenho de 6 em 6 meses, com possibilidade de progressão anual de acordo com o seu desempenho;</li><li>Salário compatível com o mercado;</li><li>Vale alimentação/refeição;</li><li>Programa de Premiação por performance.</li></ul>\n",
      "      \n",
      "Current Scraped Url:\n",
      " https://br.linkedin.com/jobs/view/analista-de-dados-growth-at-pieta-tech-3254129678?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=MhGlaPZmUOeDDb5q5Xn5hA%3D%3D&position=10&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "DEBUG:  https://br.linkedin.com/jobs/view/analista-de-dados-growth-at-pieta-tech-3254129678?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=MhGlaPZmUOeDDb5q5Xn5hA%3D%3D&position=10&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "\n",
      "        Estamos em constante expansão!<p><br></p>Com mais de 5.000 projetos homologados em 45 distribuidoras por todo Brasil e três softwares desenvolvidos, nosso propósito é levar soluções inteligentes e eficientes para o mercado fotovoltaico, além de produzir conteúdo de valor para propagar conhecimento dentro do setor.<p><br></p>E para que seja possível nos aperfeiçoarmos ainda mais, contamos e buscamos por pessoas que querem fazer a diferença e que unem as suas especialidades e experiências em prol da inovação.<p><br></p>Então, que tal fazer parte de uma energytech pioneira no mercado de energia solar no Brasil? Se você possui espírito empreendedor, aspira inovação e quer fazer parte de um time de alto desempenho, candidate-se às nossas vagas!<p><br></p>O seu desafio será:<p><br></p><ul><li></li><li>Responsável pela estruturação e gestão de dados;</li><li>Criação de dashboards e relatórios;</li><li>Integração dos dados nas plataformas;</li><li>Acompanhamento de testes;</li><li>Relatórios de testes;</li><li>Apoio técnico para automações;</li><li>Criação de hipóteses de melhoria dos processos baseadas em dados;</li><li>Mapear e propor melhorias na estratégia;</li><li>Analisar oportunidades em cada etapa do funil de marketing e vendas, identificando ações específicas para cada uma delas.</li></ul><p><br></p>O que você traz:<p><br></p><ul><li>Espírito empreendedor;</li><li>Experiência com análise de dados;</li><li>Estatística avançada;</li><li>Domínio de plataformas de automação de marketing (Active Campaign ou semelhante).</li><li>Experiência com ferramentas de análise web (Google Analytics, Hotjar, Microsoft Clarity,etc);</li><li>Conhecimento de linguagem de programação SQL;</li><li>Conhecimento em linguagem de programação Python;</li></ul><p><br></p>Será um plus se você tiver:<p><br></p><ul><li>Experiência com Startups.</li></ul><p><br></p>Algumas das nossas políticas e benefícios são:<p><br></p><ul><li>Auxílio Transporte;</li><li>Plano de Saúde - Unimed*;</li><li>Vale alimentação;</li><li>Day Off para aniversariantes;</li><li>Horário flexível;</li><li>Open Fruta;</li><li>Café expresso, capuccino, mocaccino e chocolate quente;</li><li>Parceria com estabelecimentos;</li><li>Ambiente leve e descontraído;</li><li>Espaço para descanso;</li><li>Happy Hour.</li></ul>\n",
      "      \n",
      "Current Scraped Url:\n",
      " https://br.linkedin.com/jobs/view/engenheiro-a-de-dados-j%C3%BAnior-at-dot-digital-group-3274894028?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=yal5%2B1JpVrsz9ZpyMmmDqA%3D%3D&position=11&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "DEBUG:  https://br.linkedin.com/jobs/view/engenheiro-a-de-dados-j%C3%BAnior-at-dot-digital-group-3274894028?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=yal5%2B1JpVrsz9ZpyMmmDqA%3D%3D&position=11&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "\n",
      "        <strong>Descrição</strong><p><br></p><strong><strong>🤩QUEM SOMOS?</strong></strong><p><br></p>O DOT Digital Group é pioneiro no mercado de Educação Corporativa Digital no Brasil! Já são mais de 25 anos sendo responsável pela transformação de muitos negócios que decidiram abraçar a Tecnologia e a Transformação Digital. Estamos acostumados a abraçar os desafios educacionais mais diversos – do simples ao complexo. Educação e tecnologia é o nosso negócio!<p><br></p><strong><strong>🧐O QUE FAZEMOS?</strong></strong><p><br></p>Desenvolvemos pessoas para impulsionar organizações! Produção de cursos online e trilhas de aprendizagem sob medida, estruturação de Universidades Corporativas, desenvolvimento de soluções como LMS, Immersive Learning e Gamification, desenvolvimento de conteúdo educacional para o formato digital, operações em larga escala de monitoria e tutoria, entre outras estratégias educacionais.<p><br></p><strong><strong>🤗NOSSO JEITO DOT DE SER!</strong></strong><p><br></p>Jogamos aberto e limpo, estamos no mesmo barco e não tiramos o corpo fora! Aqui <strong>respeitamos</strong> as pessoas - independente da cor, crenças, cultura, gênero, orientação afetiva e idade. Acreditamos no que fazemos e temos paixão pelo UAU. Sempre é possível fazer diferente e melhor em um ambiente de confiança. Valorizamos a autogestão, a colaboração e a busca pelo desenvolvimento contínuo. E aí, curtiu e se identificou com o jeito DOT de ser? Então #vemproDOT!<p><br></p><strong>🎯Engenheiro(a) de Dados Júnior</strong><p><br></p>Você que tem perfil analítico, curte desenvolver, testar, alinhar arquiteturas, e utilizar dados para automatização e melhorias na área, vem pro DOT! Nós acreditamos no que fazemos e buscamos alguém que embarque nessa com a gente.<p><br></p><strong>Qual o seu papel na construção dessa trilha?</strong><p><br></p><ul><li>Desenvolver ETLs e pipelines de integração de dados;</li><li>Auxiliar em desenvolver, construir, testar, manter e alinhar arquiteturas com requisitos de negócios;</li><li>Usar grandes conjuntos de dados para resolver problemas de negócios;</li><li>Contribuir e auxiliar os demais membros da equipe, oferecendo suporte e soluções técnicas.</li></ul><p><br></p><strong>Quais vivências esperamos de você?</strong><p><br></p><ul><li>Vivência em Python e SQL para manipulação de dados;</li><li>Vivência em processdamento de dados em larga escala com spark (pyspark);</li><li>Vivência em orquestração de dados com Apache Airflow.</li></ul><p><br></p><strong><u>Será Incrível Se Você Já Tiver</u></strong><p><br></p><ul><li>Vivência em Infrastructure as code (Docker, Kubernetes, Terraform);</li><li>Conhecimento em alguma ferramenta de dashboard (Data Studio, Power Bi, Tableau ou QlikView).</li></ul><p><br></p>Aqui acreditamos no lifelong learning, e desejamos que você siga em busca de aprendizado contínuo!<p><br></p><strong><u>🥳nossa Proposta De Valor</u></strong><p><br></p>E para impulsionar você a completar essa trilha com sucesso, o DOT oferece:<p><br></p><strong>Auxílios!</strong><p><br></p><ul><li>Vale alimentação e/ou refeição, com desconto de apenas 1% na folha (R$660);</li><li>Vale transporte;</li><li>Seguro de vida;</li><li>Auxílio home office (R$100);</li><li>Auxílio creche;</li><li>Headhunter (valor por indicação de colaborador);</li><li>Indicação de clientes (valor por indicação de clientes).</li></ul><p><br></p><strong>Saúde e bem estar!</strong><p><br></p><ul><li>Plano de saúde integral, sem desconto na folha (com terapia online gratuita);</li><li>Convênio odontológico;</li><li>Gympass (plataforma de saúde e bem estar);</li><li>Convênio Farmácia;</li><li>Licença maternidade estendida de 6 meses;</li><li>Licença paternidade estendida de 20 dias;</li><li>FeelingDOT sobre temas diversos (workshops sobre autoconhecimento, diversidade, inclusão e equilíbrio);</li><li>Mimos e gifts em datas comemorativas.</li></ul><p><br></p><strong>Crescimento e desenvolvimento contínuos!</strong><p><br></p><ul><li>Verba de Sophia de R$ 2.000,00 (auxílio educação);</li><li>Horas de Sophia (40 horas/ano em capacitação da sua escolha);</li><li>Verba Survival (auxílio educação no negócio);</li><li>DOTAcademy com cursos gratuitos;</li><li>Plataforma que apoia no desenvolvimento de carreira;</li><li>Mobilidade interna;</li><li>DOTHUB (desenvolvimento de lideranças);</li><li>Cultura de feedback;</li><li>DOTKnows (peer learning).</li></ul><p><br></p><strong>Clima colaborativo e descontraído!</strong><p><br></p><ul><li>Anywhereoffice: trabalhe de onde quiser;</li><li>Horário flexível;</li><li>Aprendizado contínuo;</li><li>Pessoas que é bom de estar perto;</li><li>Autonomia com responsabilidade;</li><li>Local para refeições (presencial);</li><li>Lanches, snacks, frutas, chás e café passado (presencial);</li><li>Área de convivência (presencial);</li><li>Momentos de integração e festas.</li></ul><p><br></p>E muuuito mais! ;)<p><br></p><strong>Características</strong> <strong>Tipo de Contratação</strong><p><br></p>Tempo integral<p><br></p><strong>Remuneração</strong><p><br></p>Competitivo<p><br></p><strong>Outras Características</strong><p><br></p>Trabalho remoto<p><br></p>\n",
      "      \n",
      "Current Scraped Url:\n",
      " https://br.linkedin.com/jobs/view/engenheiro-de-dados-at-fator-wow%21-3274713572?refId=M3gvRWmiPk9RfbiFbr9yRA%3D%3D&trackingId=hQbXg7wqOtG2JZY0hy2Alg%3D%3D&position=12&pageNum=0&trk=public_jobs_jserp-result_search-card\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [248], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m url \u001b[38;5;241m=\u001b[39m job[\u001b[38;5;241m5\u001b[39m]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent Scraped Url:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,url)\n\u001b[0;32m---> 19\u001b[0m wd\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEBUG: \u001b[39m\u001b[38;5;124m\"\u001b[39m, wd\u001b[38;5;241m.\u001b[39mcurrent_url)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Loop verifying if a redirect has occurred and then undoes it.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/git/web_scraping_jobs/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, url: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[39m    Loads a web page in the current browser session.\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mGET, {\u001b[39m'\u001b[39;49m\u001b[39murl\u001b[39;49m\u001b[39m'\u001b[39;49m: url})\n",
      "File \u001b[0;32m~/Desktop/git/web_scraping_jobs/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:426\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    423\u001b[0m         params[\u001b[39m'\u001b[39m\u001b[39msessionId\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession_id\n\u001b[1;32m    425\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_value(params)\n\u001b[0;32m--> 426\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcommand_executor\u001b[39m.\u001b[39;49mexecute(driver_command, params)\n\u001b[1;32m    427\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[1;32m    428\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_handler\u001b[39m.\u001b[39mcheck_response(response)\n",
      "File \u001b[0;32m~/Desktop/git/web_scraping_jobs/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py:344\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    342\u001b[0m data \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mdump_json(params)\n\u001b[1;32m    343\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_url\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 344\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(command_info[\u001b[39m0\u001b[39;49m], url, body\u001b[39m=\u001b[39;49mdata)\n",
      "File \u001b[0;32m~/Desktop/git/web_scraping_jobs/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py:366\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    363\u001b[0m     body \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeep_alive:\n\u001b[0;32m--> 366\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conn\u001b[39m.\u001b[39;49mrequest(method, url, body\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[1;32m    367\u001b[0m     statuscode \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mstatus\n\u001b[1;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/git/web_scraping_jobs/venv/lib/python3.10/site-packages/urllib3/request.py:78\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_encode_url(\n\u001b[1;32m     75\u001b[0m         method, url, fields\u001b[39m=\u001b[39mfields, headers\u001b[39m=\u001b[39mheaders, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39murlopen_kw\n\u001b[1;32m     76\u001b[0m     )\n\u001b[1;32m     77\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_encode_body(\n\u001b[1;32m     79\u001b[0m         method, url, fields\u001b[39m=\u001b[39;49mfields, headers\u001b[39m=\u001b[39;49mheaders, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49murlopen_kw\n\u001b[1;32m     80\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/git/web_scraping_jobs/venv/lib/python3.10/site-packages/urllib3/request.py:170\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m extra_kw[\u001b[39m\"\u001b[39m\u001b[39mheaders\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mupdate(headers)\n\u001b[1;32m    168\u001b[0m extra_kw\u001b[39m.\u001b[39mupdate(urlopen_kw)\n\u001b[0;32m--> 170\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kw)\n",
      "File \u001b[0;32m~/Desktop/git/web_scraping_jobs/venv/lib/python3.10/site-packages/urllib3/poolmanager.py:376\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    374\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[1;32m    375\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(method, u\u001b[39m.\u001b[39;49mrequest_uri, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    378\u001b[0m redirect_location \u001b[39m=\u001b[39m redirect \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mget_redirect_location()\n\u001b[1;32m    379\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[0;32m~/Desktop/git/web_scraping_jobs/venv/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/git/web_scraping_jobs/venv/lib/python3.10/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/git/web_scraping_jobs/venv/lib/python3.10/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1375\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load further details\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "filename = 'linkedin_jobs_data-3.csv'\n",
    "# Opening csv file to read job links\n",
    "\n",
    "with open(filename, 'r') as csvfile: \n",
    "    csvreader = csv.reader(csvfile)\n",
    "    next(csvreader)\n",
    "\n",
    "    # Indicates which job is going to be updated\n",
    "    CSVtabelIndex = 0\n",
    "\n",
    "    for job in csvreader:\n",
    "        \n",
    "        url = job[5]\n",
    "        print(\"Current Scraped Url:\\n\",url)\n",
    "        wd.get(url)\n",
    "\n",
    "        print(\"DEBUG: \", wd.current_url)\n",
    "\n",
    "        # Loop verifying if a redirect has occurred and then undoes it.\n",
    "        while 'authwall' in wd.current_url:\n",
    "            print(wd.current_url)\n",
    "            time.sleep(2)\n",
    "            wd.get(url)\n",
    "\n",
    "        # Selecting elements that hold the job description (about)\n",
    "        jd0 = wd.find_element(By.CLASS_NAME, value='show-more-less-html__markup').get_attribute(\"innerHTML\")\n",
    "        print(jd0)\n",
    "\n",
    "        # Selecting elements that hold job 4 criterias \n",
    "        job = wd.find_elements(By.CLASS_NAME, value='description__job-criteria-item')\n",
    "\n",
    "        seniority0 = job[0].find_element(By.CLASS_NAME, value='description__job-criteria-text').text\n",
    "        \n",
    "        emp_type0 = job[1].find_element(By.CLASS_NAME, value='description__job-criteria-text').text\n",
    "        \n",
    "        job_func0 = job[2].find_element(By.CLASS_NAME, value='description__job-criteria-text').text\n",
    "\n",
    "        industries0 = job[3].find_element(By.CLASS_NAME, value='description__job-criteria-text').text\n",
    "\n",
    "        # Adding new information to the existing jobs \n",
    "        jd[CSVtabelIndex] = jd0\n",
    "        seniority[CSVtabelIndex] = seniority0\n",
    "        emp_type[CSVtabelIndex]= emp_type0\n",
    "        job_func[CSVtabelIndex] = job_func0         \n",
    "        industries[CSVtabelIndex] = industries0\n",
    "\n",
    "        CSVtabelIndex = CSVtabelIndex + 1\n",
    "        \n",
    "        time.sleep(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data into DataFrame for further analysis\n",
    "job_data = pd.DataFrame({'ID': job_id,\n",
    "                         'Date': date,\n",
    "                         'Company': company_name,\n",
    "                         'Title': job_title,\n",
    "                         'Location': location,\n",
    "                         'Link': job_link,\n",
    "                         'Description': jd,\n",
    "                         'Level': seniority,\n",
    "                         'Type': emp_type,\n",
    "                         'Function': job_func,\n",
    "                         'Industry': industries\n",
    "                         })\n",
    "\n",
    "job_data.to_csv('linkedin_jobs_data-3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-virtualenv-name",
   "language": "python",
   "name": "my-virtualenv-name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
